<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id><journal-title>BMC Bioinformatics</journal-title><issn pub-type="epub">1471-2105</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">15511294</article-id><article-id pub-id-type="pmc">PMC543472</article-id><article-id pub-id-type="publisher-id">1471-2105-5-172</article-id><article-id pub-id-type="doi">10.1186/1471-2105-5-172</article-id><article-categories><subj-group subj-group-type="heading"><subject>Methodology Article</subject></subj-group></article-categories><title-group><article-title>Incremental genetic K-means algorithm and its application in gene expression data analysis</article-title></title-group><contrib-group><contrib id="A1" contrib-type="author"><name><surname>Lu</surname><given-names>Yi</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>luyi@wayne.edu</email></contrib><contrib id="A2" contrib-type="author"><name><surname>Lu</surname><given-names>Shiyong</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>shiyong@cs.wayne.edu</email></contrib><contrib id="A3" contrib-type="author"><name><surname>Fotouhi</surname><given-names>Farshad</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>fotouhi@cs.wayne.edu</email></contrib><contrib id="A4" corresp="yes" contrib-type="author"><name><surname>Deng</surname><given-names>Youping</given-names></name><xref ref-type="aff" rid="I2">2</xref><email>youping.deng@usm.edu</email></contrib><contrib id="A5" contrib-type="author"><name><surname>Brown</surname><given-names>Susan J</given-names></name><xref ref-type="aff" rid="I3">3</xref><email>sjbrown@ksu.edu</email></contrib></contrib-group><aff id="I1"><label>1</label>Dept. of Computer Science, Wayne State University, Detroit, MI 48202, USA</aff><aff id="I2"><label>2</label>Department of Biological Sciences, the University of Southern Mississippi, Hattiesburg 39406, USA</aff><aff id="I3"><label>3</label>Division of Biology, Kansas State University, Manhattan, KS 66506, USA</aff><pub-date pub-type="collection"><year>2004</year></pub-date><pub-date pub-type="epub"><day>28</day><month>10</month><year>2004</year></pub-date><volume>5</volume><fpage>172</fpage><lpage>172</lpage><ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1471-2105/5/172"/><history><date date-type="received"><day>10</day><month>3</month><year>2004</year></date><date date-type="accepted"><day>28</day><month>10</month><year>2004</year></date></history><copyright-statement>Copyright &#x000a9; 2004 Lu et al; licensee BioMed Central Ltd.</copyright-statement><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0"/>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</p></license><abstract><sec><title>Background</title><p>In recent years, clustering algorithms have been effectively applied in molecular biology for gene expression data analysis. With the help of clustering algorithms such as K-means, hierarchical clustering, SOM, etc, genes are partitioned into groups based on the similarity between their expression profiles. In this way, functionally related genes are identified. As the amount of laboratory data in molecular biology grows exponentially each year due to advanced technologies such as Microarray, new efficient and effective methods for clustering must be developed to process this growing amount of biological data.</p></sec><sec><title>Results</title><p>In this paper, we propose a new clustering algorithm, <italic>Incremental Genetic K-means Algorithm (IGKA)</italic>. IGKA is an extension to our previously proposed clustering algorithm, the Fast Genetic K-means Algorithm (<italic>FGKA</italic>). IGKA outperforms FGKA when the mutation probability is small. The main idea of IGKA is to calculate the objective value Total Within-Cluster Variation (TWCV) and to cluster centroids incrementally whenever the mutation probability is small. IGKA inherits the salient feature of FGKA of always converging to the global optimum. C program is freely available at <ext-link ext-link-type="uri" xlink:href="http://database.cs.wayne.edu/proj/FGKA/index.htm."/></p></sec><sec><title>Conclusions</title><p>Our experiments indicate that, while the IGKA algorithm has a convergence pattern similar to FGKA, it has a better time performance when the mutation probability decreases to some point. Finally, we used IGKA to cluster a yeast dataset and found that it increased the enrichment of genes of similar function within the cluster.</p></sec></abstract></article-meta></front><body><sec><title>Background</title><p>In recent years, clustering algorithms have been effectively applied in molecular biology for gene expression data analysis (see [<xref ref-type="bibr" rid="B1">1</xref>] for an excellent survey). With the advancement in Microarray technology, it is now possible to observe the expression levels of thousands of genes simultaneously when the cells experience specific conditions or undergo specific processes. Clustering algorithms are used to partition genes into groups based on the similarity between their expression profiles. In this way, functionally related genes are identified. As the amount of laboratory data in molecular biology grows exponentially each year due to advanced technologies such as Microarray, new efficient and effective methods for clustering must be developed to process this growing amount of biological data.</p><p>Among the various clustering algorithms, K-means [<xref ref-type="bibr" rid="B2">2</xref>] is one of the most popular methods used in gene expression data analysis due to its high computational performance. However, it is well known that K-means might converge to a local optimum, and its result is subject to the initialization process, which randomly generates the initial clustering. In other words, different runs of K-means on the same input data might produce different solutions.</p><p>A number of researchers have proposed genetic algorithms [<xref ref-type="bibr" rid="B3">3</xref>-<xref ref-type="bibr" rid="B6">6</xref>] for clustering. The basic idea is to simulate the evolution process of nature and evolve solutions from one generation to the next. In contrast to K-means, which might converge to a local optimum, these genetic algorithms are insensitive to the initialization process and always converge to the global optimum eventually. However, these algorithms are usually computationally expensive which impedes the wide application of them in practice such as in gene expression data analysis.</p><p>Recently, Krishna and Murty proposed a new clustering method called <italic>Genetic K-means Algorithm (GKA) </italic>[<xref ref-type="bibr" rid="B7">7</xref>], which hybridizes a genetic algorithm with the K-means algorithm. This hybrid approach combines the robust nature of the genetic algorithm with the high performance of the K-means algorithm. As a result, GKA will always converge to the global optimum faster than other genetic algorithms.</p><p>In [<xref ref-type="bibr" rid="B8">8</xref>], we proposed a faster version of GKA, FGKA that features several improvements over GKA including an efficient evaluation of the objective value TWCV (Total Within-Cluster Variation), avoiding illegal string elimination overhead, and a simplification of the mutation operator. These improvements result that FGKA runs 20 times faster than GKA [<xref ref-type="bibr" rid="B9">9</xref>]. In this paper, we propose an extension to FGKA, <italic>Incremental Genetic K-means Algorithm (IGKA) </italic>that inherits all the advantages of FGKA including the convergence to the global optimum, and outperforms FGKA when the mutation probability is small. The main idea of IGKA is to calculate the objective value TWCV and to cluster centroids incrementally. We then propose a <italic>Hybrid Genetic K-means Algorithm </italic>(HGKA) that combines the benefits of FGKA and IGKA. We show that clustering of microarray data by IGKA method has more tendencies to group the genes with the same functional category into a given cluster.</p></sec><sec><title>Results</title><p>Our experiments were conducted on a Dell PowerEdge 400SC PC machine with 2.24G Hz CPU and 512 M RAM. Three algorithms, FGKA, IGKA and HGKA algorithm were implemented in C language. GKA has convergence pattern similar to FGKA and IGKA, but its time performance is worse than FGKA, see [<xref ref-type="bibr" rid="B9">9</xref>] for more details. In the following, we compare the time performance of FGKA and IGKA along different mutation probabilities, and then we compare the convergence property of four algorithms, IGKA, FGKA, K-means and SOM (Self Organizing Map). At the end, we check how we can combine IGKA and FGKA algorithm together to obtain a better performance.</p><sec><title>Data sets</title><p>The two data sets used to conduct our experiments are serum data, <italic>fig2data</italic>, introduced in [<xref ref-type="bibr" rid="B11">11</xref>]and yeast data, <italic>chodata</italic>, introduced in [<xref ref-type="bibr" rid="B2">2</xref>]. The <italic>fig2data </italic>data set contains expression data for 517 genes. Each gene has 19 expression data ranges from 15 minutes to 24 hours. In other words, the number of features <italic>D </italic>is 19. According to [<xref ref-type="bibr" rid="B11">11</xref>], 517 genes can be divided into 10 groups. The <italic>chodata </italic>is a yeast dataset, composed of expression data for 2907 genes and the expression data for each gene ranges 0 minutes to 160 minutes, which means that the number of features D is 15. According to the description in [<xref ref-type="bibr" rid="B2">2</xref>], the genes can be divided into 30 groups. Since the IGKA is a stochastic algorithm, for each experiment in this study, we obtain the results by averaging 10 independent run of the program. The mutation probability, the generation number, the population number all affect the performance and convergence of FGKA and IGKA. The detailed discussion of the parameters setting can be found in [<xref ref-type="bibr" rid="B8">8</xref>]. In this paper, we simply adopt the result in [<xref ref-type="bibr" rid="B8">8</xref>], the population number is set to 50, and the generation number is set to 100. These parameter setting are safe enough to guarantee the algorithm converge to the optima.</p></sec><sec><title>Comparison of IGKA with FGKA on time performance</title><p>As indicated in the implementation section, the mutation probability has great impact on IGKA algorithm. We check the performance impact on IGKA in this section, and the convergence in the next section. Figure <xref ref-type="fig" rid="F2">2</xref> shows the time performance results for these two algorithms. We can see that when the mutation probability increases, the running time increases accordingly for both algorithms. However, when the mutation probability is smaller than some threshold (0.005 for <italic>fig2data</italic>, and 0.0005 for <italic>chodata</italic>), IGKA has a better performance. Figure <xref ref-type="fig" rid="F2">2</xref> also indicates the thresholds vary from one dataset to another. In order to achieve better performance of IGKA in large data set, mutation probability may need to be set to smaller than that in small data set. For example, in larger data set <italic>chodata</italic>, we should set the mutation probability to 0.0005 to have IGKA outperform FGKA. On the other hand, in order to have IGKA outperform than FGKA, we only need to set the mutation probability to 0.005 in the small data set <italic>fig2data</italic>. In general, the threshold value depends on the number of patterns and the number of features in the data set. It is easy to understand that the performance gained in IGKA is mainly dependent on how many patterns change their cluster memberships. So, in a large data set, even small number of mutation probability may cause many patterns change their cluster memberships.</p></sec><sec><title>Comparison of IGKA with FGKA, K-means and SOM on convergence</title><p>Figures <xref ref-type="fig" rid="F3">3(A)</xref> and <xref ref-type="fig" rid="F3">3(B)</xref> show the convergence of IGKA versus FGKA across different mutation probabilities based on <italic>fig2data </italic>and <italic>chodata</italic>, respectively. These two algorithms have similar convergence results. When the mutation probability changes in these two data sets, it has little impact on these two algorithms during the range that is given in Figure <xref ref-type="fig" rid="F3">3</xref>, except for the case when the mutation probability is too large. It gives an opportunity to choose IGKA with better performance without losing the convergence benefit.</p><p>We also make an interesting comparison of IGKA with FGKA, K-means and SOM on TWCV convergence. We treat each algorithm as a black box. Two data sets, the <italic>fig2data </italic>and <italic>chodata</italic>, are fed into the algorithms, and the clustering results are exported as a text file. We then use an in-house program to calculate the TWCVs for each result. The experiments on K-means and SOM algorithm are conducted on an open source software [<xref ref-type="bibr" rid="B12">12</xref>]. As we can see in Table <xref ref-type="table" rid="T2">2</xref>, the IGKA and FGKA have almost similar convergence result, and much better than the convergence of K-means algorithm. The TWCV convergence of SOM is much worse than the others although these four algorithms all use Euclidian distance as their measurement. The reason why we do not include another popular clustering algorithm, hierarchical clustering algorithm is because it is hard to define the boundary among the nested clusters, which means we cannot simply define the number of cluster before running the program.</p></sec><sec><title>Combination of IGKA with FGKA</title><p>Figure <xref ref-type="fig" rid="F4">4</xref> compares three algorithms, IGKA, FGKA and HGKA, based on the running times for 100 iterations. The mutation probability is set to 0.0001 for all three algorithms. It is clearly that the running time for each iteration of FGKA is much stable than others. On the other hand, the running time for IGKA is much higher than FGKA at the beginning because there are a large number of patterns change their cluster belonging during the K-means operator which cause the IGKA spend a lot of computation time. However, the running time for each iteration of IGKA decrease very sharply at late iterations. The HGKA combines the advantage of two algorithms. The turning point when HGKA uses IGKA instead of FGKA as work horse is highly data dependent. In this particular case, we check the computation time every 15 iterations. The result shows that the performance can be really improved by using HGKA when the mutation probability is small.</p></sec></sec><sec><title>Discussion</title><p>The clustering results of <italic>chodata </italic>using our IGKA algorithm were evaluated according to the scheme of gene classification of MIPS Yeast Genome Database [<xref ref-type="bibr" rid="B13">13</xref>]. We found that genes of similar function were grouped into the same cluster. Table <xref ref-type="table" rid="T3">3</xref> shows 8 main clusters including 16 functional categories of genes. The results are comparable to the data of [<xref ref-type="bibr" rid="B2">2</xref>]. The absolute number of ORFs with functional categories in some cluster may not be always higher than Tavazoie's result, but we found that the percentage of the ORF number within functional category of each cluster in the total ORF number of each cluster is usually higher than Tavazoie's result in most cases. For example, they found that there are 40 genes in the functional category of nuclear organization distributed in their cluster 2, in which there are 186 ORFs, so their percentage is 21.5%. But we found there are 50 genes of the same functional category distributed in our cluster 16, in which there are only 133 ORFs, and our percentage is 37.6% that is significantly higher than 21.5%.</p><p>Most interestingly, we found a remarkable enrichment of ORFs for the functional category of organization of mitochondria. They are mainly located in two clusters: cluster 3 and cluster 18. Cluster 3 has 156 ORFs in total, and 111 ORFs belong to the category, resulting in a very high percentage, 71.2%. Cluster 18, has 184 ORFs in total, in which there are 105 ORFs belonging to the category and the percentage is 57.1%. The percentage of ORFs within the same function category is only 18.8% in the previous paper. It looks that our IGKA method is more likely to increase the degree of enrichment of the genes within functional categories, and to make more biological sense. We also found a new function category: lipid and fatty isoprenoid metabolism distributed in cluster 25, which was not listed in Tavazoie's paper.</p></sec><sec><title>Conclusions</title><p>In this paper, we propose a new clustering algorithm called <italic>Incremental Genetic K-means Algorithm (IGKA)</italic>. IGKA is an extension of FGKA, which in turn was inspired by the Genetic K-means Algorithm (GKA) proposed by Krishna and Murty. The IGKA inherits the advantages of FGKA, and it outperforms FGKA when the mutation probability is small. Since both FGKA and IGKA might outperform each other, a hybrid approach that combines the benefits of them is very desirable. Our experimental results showed that not only the performance of our algorithm is improved but also the clustering result with gene expression data has some interesting biological discovery.</p></sec><sec sec-type="methods"><title>Methods</title><p>The problem of clustering gene expression data consists of <italic>N </italic>genes and their corresponding <italic>N </italic>patterns. Each pattern is a vector of <italic>D </italic>dimensions recording the expression levels of the genes under each of the <italic>D </italic>monitored conditions or at each of the <italic>D </italic>time points. The goal of IGKA algorithm is to partition the <italic>N </italic>patterns into user-defined <italic>K </italic>groups, such that this partition minimizes the Total Within-Cluster Variation (<italic>TWCV</italic>, also called <italic>square-error </italic>in the literature), which is defined as follows.</p><p>Let <inline-graphic xlink:href="1471-2105-5-172-i1.gif"/> be the <italic>N </italic>patterns, and <italic>X</italic><sub><italic>nd </italic></sub>denotes the <italic>dth </italic>feature of pattern <italic>X</italic><sub><italic>n</italic></sub>(<italic>n </italic>= 1,...<italic>N</italic>). Each partition is represented by a string, a sequence of numbers <italic>a</italic><sub>1</sub>....<italic>a</italic><sub><italic>N</italic></sub>,, where <italic>a</italic><sub><italic>n </italic></sub>is the number of the cluster that pattern <inline-graphic xlink:href="1471-2105-5-172-i2.gif"/> belongs to in this partition. Let <italic>G</italic><sub><italic>k </italic></sub>denote the <italic>kth </italic>cluster and <italic>Z</italic><sub><italic>k </italic></sub>denote the number of patterns in <italic>G</italic><sub><italic>k</italic></sub>. The centroid <italic>c</italic><sub><italic>k </italic></sub>= (<italic>c</italic><sub><italic>k</italic>1</sub>, <italic>c</italic><sub><italic>k</italic>2</sub>,...,<italic>c</italic><sub><italic>kD</italic></sub>) of cluster <italic>G</italic><sub><italic>k </italic></sub>is defined as <inline-graphic xlink:href="1471-2105-5-172-i3.gif"/>, (<italic>d </italic>= 1,2,...<italic>D</italic>) where <italic>SF</italic><sub><italic>kd </italic></sub>is the sum of the <italic>d</italic>th features of all the patterns in <italic>G</italic><sub><italic>k</italic></sub>. and we use <inline-graphic xlink:href="1471-2105-5-172-i4.gif"/> to denote the vector of sum of all patterns in cluster <italic>G</italic><sub><italic>k</italic></sub>.</p><p>IGKA maintains a population (set) of <italic>Z </italic>coded solutions, where <italic>Z </italic>is a parameter specified by the user. Each solution, also called a <italic>chromosome</italic>, is coded by a string <italic>a</italic><sub>1</sub>...<italic>a</italic><sub><italic>N </italic></sub>of length <italic>N</italic>, where each <italic>a</italic><sub><italic>n</italic></sub>, which is called an <italic>allele</italic>, corresponds to a gene expression data pattern and takes a value from {1, 2, ..., K} representing the cluster number to which the corresponding pattern belongs. For example, a<sub>1</sub>a<sub>2</sub>a<sub>3</sub>a<sub>4</sub>a<sub>5</sub>= "33212" encodes a partition of 5 patterns in which, patterns <inline-graphic xlink:href="1471-2105-5-172-i5.gif"/> and <inline-graphic xlink:href="1471-2105-5-172-i6.gif"/> belong to cluster 3, patterns <inline-graphic xlink:href="1471-2105-5-172-i7.gif"/> and <inline-graphic xlink:href="1471-2105-5-172-i8.gif"/> belong to cluster 2, and pattern <inline-graphic xlink:href="1471-2105-5-172-i9.gif"/> belongs to cluster 1.</p><sec><title>Definition (Legal strings, Illegal strings)</title><p>Given a partition <italic>S</italic><sub><italic>z </italic></sub>= <italic>a</italic><sub>1 </sub>....<italic>a</italic><sub><italic>N</italic></sub>, let <italic>e</italic>(<italic>S</italic><sub><italic>z</italic></sub>) be the number of non-empty clusters in <italic>S</italic><sub><italic>z </italic></sub>divided by <italic>K</italic>, <italic>e</italic>(<italic>S</italic><sub><italic>z</italic></sub>) is called <italic>legality ratio</italic>. We say string <italic>S</italic><sub><italic>z </italic></sub>is <italic>legal </italic>if e(<italic>S</italic><sub><italic>z</italic></sub>) = 1, and <italic>illegal </italic>otherwise.</p><p>Hence, an illegal string represents a partition in which some clusters are empty. For example, given <italic>K </italic>= 3, the string a<sub>1</sub>a<sub>2</sub>a<sub>3</sub>a<sub>4</sub>a<sub>5 </sub>= "23232" is illegal because cluster 1 is empty.</p><p>Figure <xref ref-type="fig" rid="F1">1</xref> gives the flowchart of IGKA. It starts with the initialization phase, which generates the initial population <italic>P</italic><sub>0</sub>. The population in the next generation <italic>P</italic><sub><italic>i </italic>+ <italic>1 </italic></sub>is obtained by applying genetic operators on the current population <italic>P</italic><sub><italic>i</italic></sub>. The evolution takes place until a terminating condition is reached. The following genetic operators are used in IGKA: the selection, the mutation and the K-means operator.</p></sec><sec><title>Selection operator</title><p>We use the so-called <italic>proportional selection </italic>for the selection operator in which, the population of the next generation is determined by <italic>Z </italic>independent random experiments. Each experiment randomly selects a solution from the current population (S<sub>1</sub>, S<sub>2</sub>, ..., <italic>S</italic><sub><italic>z</italic></sub>) according to the probability distribution (<italic>p</italic><sub>1</sub>, <italic>p</italic><sub>2</sub>, ..., <italic>p</italic><sub><italic>K</italic></sub>) defined by <inline-graphic xlink:href="1471-2105-5-172-i10.gif"/>(<italic>z </italic>= 1,...<italic>Z</italic>), where <italic>F</italic>(<italic>S</italic><sub><italic>z</italic></sub>) denotes the fitness value of solution <italic>S</italic><sub><italic>z </italic></sub>with respect to the current population and will be defined in the next paragraph.</p><p>Various fitness functions have been defined in the literature [<xref ref-type="bibr" rid="B10">10</xref>] in which the fitness value of each solution in the current population reflects its merit to survive in the next generation. In our context, the objective is to minimize the Total Within-Cluster Variation (<italic>TWCV</italic>). Therefore, solutions with smaller <italic>TWCV</italic>s should have higher probabilities for survival and should be assigned with greater fitness values. In addition, illegal strings are less desirable and should have lower probabilities for survival, and thus should be assigned with lower fitness values. We define fitness value of solution <italic>S</italic><sub><italic>z</italic></sub>, <italic>F</italic>(<italic>S</italic><sub><italic>z</italic></sub>) as</p><p><inline-graphic xlink:href="1471-2105-5-172-i11.gif"/></p><p>where <italic>TWCV</italic><sub><italic>max </italic></sub>is the maxim <italic>TWCV </italic>that has been encountered till the present generation, <italic>F</italic><sub><italic>min </italic></sub>is the smallest fitness value of the legal strings in the current population if they exist, otherwise <italic>F</italic><sub><italic>min </italic></sub>is defined as 1. The definition of fitness function in GKA [<xref ref-type="bibr" rid="B7">7</xref>] paper inspired our definition, but we incorporate the idea of permitting illegal strings by defining the fitness values for them.</p><p>The intuition behind this fitness function is that, each solution will have a probability to survive by being assigned with a positive fitness value, but a solution with a smaller TWCV has a greater fitness value and hence has a higher probability to survive. Illegal solutions are allowed to survive too but with lower fitness values than all legal solutions in the current population. Illegal strings that have more empty clusters are assigned with smaller fitness values and hence have lower probabilities for survival. The reason we still allow illegal solution survive with low probability is that we believe the illegal solution may mutate to a good solution and the cost of maintain the illegal solution is very low.</p><p>We assume that the <italic>TWCV </italic>for each solution <italic>S</italic><sub><italic>z </italic></sub>(denoted by <italic>S</italic><sub><italic>z</italic></sub>.<italic>TWCV</italic>) and the maximum TWCV (denoted by <italic>TWCV</italic><sub><italic>max</italic></sub>), have already been calculated before the selection operator is applied.</p></sec><sec><title>Mutation operator</title><p>Given a solution (chromosome) that is encoded by <italic>a</italic><sub>1 </sub>....<italic>a</italic><sub><italic>N</italic></sub>, the mutation operator mutates each allele <italic>a</italic><sub><italic>n</italic></sub>(<italic>n </italic>= 1, ..., <italic>N</italic>) to a new value <italic>a</italic><sub><italic>n </italic></sub>(<italic>a</italic><sub><italic>n </italic></sub>might be equal to <italic>a</italic><sub><italic>n</italic></sub>) with probability <italic>MP </italic>respectively and independently, where 0 &#x0003c;<italic>MP </italic>&#x0003c; 1 is a parameter called the <italic>mutation probability </italic>that is specified by the user. The mutation operator is very important to help reach better solutions. From the perspective of the evolutional theory, offsprings produced by mutations might be superior to their parents. More importantly, the mutation operator performs the function of shaking the algorithm out of a local optimum, and moving it towards the global optimum.</p><p>Recall that in solution <italic>a</italic><sub>1 </sub>....<italic>a</italic><sub><italic>N</italic></sub>, each allele <italic>a</italic><sub><italic>n </italic></sub>corresponds to a pattern <inline-graphic xlink:href="1471-2105-5-172-i2.gif"/> and its value indicates the number of the cluster to which <inline-graphic xlink:href="1471-2105-5-172-i2.gif"/> belongs. During mutation, we replace allele <italic>a</italic><sub><italic>n </italic></sub>by <italic>a</italic><sub><italic>n</italic></sub>' for <italic>n </italic>= 1,...,<italic>N </italic>simultaneously, where <italic>a</italic><sub><italic>n </italic></sub>is a number randomly selected from (1,....,K) with the probability distribution (<italic>p</italic><sub>1</sub>, <italic>p</italic><sub>2</sub>, ..., <italic>p</italic><sub><italic>K</italic></sub>) defined by:</p><p><inline-graphic xlink:href="1471-2105-5-172-i12.gif"/></p><p>where <inline-graphic xlink:href="1471-2105-5-172-i13.gif"/> is the Euclidean distance between pattern <inline-graphic xlink:href="1471-2105-5-172-i2.gif"/> and the centroid <italic>c</italic><sub><italic>k </italic></sub>of the <italic>k</italic>th cluster, and <inline-graphic xlink:href="1471-2105-5-172-i14.gif"/>. If the <italic>k</italic>th cluster is empty, then <inline-graphic xlink:href="1471-2105-5-172-i13.gif"/> is defined as 0. The bias 0.5 is introduced to avoid divide-by-zero error in the case that all patterns are equal and are assigned to the same cluster in the given solution. Our definition of the mutation operator is similar to the one defined in the GKA paper [<xref ref-type="bibr" rid="B7">7</xref>]. However, we account for illegal strings, which are not allowed in the GKA algorithm.</p><p>The above mutation operator is defined such that (1) <inline-graphic xlink:href="1471-2105-5-172-i2.gif"/> might be reassigned randomly to each cluster with a positive probability; (2) the probability of changing allele value <italic>a</italic><sub><italic>n </italic></sub>to a cluster number <italic>k </italic>is greater if <inline-graphic xlink:href="1471-2105-5-172-i2.gif"/> is closer to the centroid of the <italic>k</italic>th cluster <italic>G</italic><sub><italic>k</italic></sub>; and (3) empty clusters are viewed as the closest clusters to <inline-graphic xlink:href="1471-2105-5-172-i2.gif"/>. The first property ensures that an arbitrary solution, including the global optimum, might be generated by the mutation from the current solution with a positive probability; the second property encourages that each <inline-graphic xlink:href="1471-2105-5-172-i2.gif"/> is moving towards a closer cluster with a higher probability; the third property promotes the probability of converting an illegal solution to a legal one. These properties are essential to guarantee that IGKA will eventually converge to the global optimum fast.</p></sec><sec><title>K-means operator</title><p>In order to speed up the convergence process, one step of the classical K-means algorithm, which we call <italic>K-means operator (KMO) </italic>is introduced. Given a solution that is encoded by <italic>a</italic><sub>1 </sub>....<italic>a</italic><sub><italic>N</italic></sub>, we replace <italic>a</italic><sub><italic>n </italic></sub>by <italic>a</italic><sub><italic>n</italic></sub>' for <italic>n </italic>= 1,...,<italic>N </italic>simultaneously, where <italic>a</italic><sub><italic>n</italic></sub>' is the number of the cluster whose centroid is closest to <inline-graphic xlink:href="1471-2105-5-172-i2.gif"/> in Euclidean distance. More formally, <inline-graphic xlink:href="1471-2105-5-172-i15.gif"/></p><p>To accommodate illegal strings, we define <inline-graphic xlink:href="1471-2105-5-172-i13.gif"/> = +&#x0221e; if the <italic>k</italic>th cluster is empty. This definition is different from mutation operator, in which we defined <inline-graphic xlink:href="1471-2105-5-172-i13.gif"/> = 0 if the <italic>k</italic>th cluster is empty. The motivation for this new definition here is that we want to avoid reassigning <italic>all </italic>patterns to empty clusters. Therefore, illegal string will remain illegal after the application of KMO.</p><p>In the following, we first present FGKA algorithm that is proposed in [<xref ref-type="bibr" rid="B9">9</xref>]. We then describe the motivation for IGKA based on the idea of incremental calculation of TWCV and centroids. Finally, we present a hybrid approach that combines the benefits of FGKA and IGKA.</p></sec><sec><title>Fast Genetic K-Means Algorithm (FGKA)</title><p>FGKA shares the same flowchart of IGKA given in Figure <xref ref-type="fig" rid="F1">1</xref>. It starts with the initialization of population <italic>P</italic><sub>0 </sub>with <italic>Z </italic>solutions. For each generation <italic>P</italic><sub><italic>i</italic></sub>, we apply the three operators, selection, mutation and K-means operator sequentially which generate population <inline-graphic xlink:href="1471-2105-5-172-i16.gif"/>, <inline-graphic xlink:href="1471-2105-5-172-i17.gif"/>, and <italic>P</italic><sub><italic>i </italic>+ 1 </sub>respectively. This process is repeated for <italic>G </italic>iterations, each of which corresponds to one generation of solutions. The best solution so far is observed and recorded in <italic>S</italic><sub><italic>o </italic></sub>before the selection operator. <italic>S</italic><sub><italic>o </italic></sub>is returned as the output solution when FGKA terminates.</p></sec><sec><title>Incremental Genetic K-Means Algorithm (IGKA)</title><p>Although FGKA outperforms GKA significantly, it suffers from a potential disadvantage. If the mutation probability is small, then the number of allele changes will be small, and the cost of calculating centroids and TWCV from scratch can be much more expensive than calculating them in an incremental fashion. As a simple example, if a pattern <inline-graphic xlink:href="1471-2105-5-172-i2.gif"/> is reassigned from cluster <italic>k </italic>to cluster <italic>k'</italic>, then only the centroids and <italic>WCV</italic>s of these two clusters need to be recalculated. Furthermore, the centroids of these two clusters can be calculated incrementally since the memberships of other patterns have not changed; The <italic>TWCV </italic>can be calculated incrementally as well since the <italic>WCV</italic>s of other clusters have not changed. In the following, we describe how we can calculate <italic>TWCV </italic>and cluster centroids <inline-graphic xlink:href="1471-2105-5-172-i18.gif"/> incrementally.</p><p>In order to obtain the new centroid <inline-graphic xlink:href="1471-2105-5-172-i18.gif"/>, we maintain the difference values of <italic>Z</italic><sub><italic>k</italic></sub><sup>&#x00394;</sup>, <inline-graphic xlink:href="1471-2105-5-172-i19.gif"/> for old solution and new solution when allele changes. With these two values, incremental update of <italic>Z</italic><sub><italic>k </italic></sub>and <inline-graphic xlink:href="1471-2105-5-172-i4.gif"/> can be achieved as <italic>Z</italic><sub><italic>k </italic></sub>= <italic>Z</italic><sub><italic>k </italic></sub>+ <italic>Z</italic><sub><italic>k</italic></sub><sup>&#x00394;</sup>, and <inline-graphic xlink:href="1471-2105-5-172-i20.gif"/>. Then the new centroids for new solution <inline-graphic xlink:href="1471-2105-5-172-i18.gif"/> can be achieved by <inline-graphic xlink:href="1471-2105-5-172-i21.gif"/>.</p><p>Similarly, in order to obtain the new <italic>TWCV</italic>, we can maintain a difference value <italic>TWCV</italic><sup>&#x00394; </sup>that denotes the difference between old <italic>TWCV </italic>and new TWCV for one solution. It is obvious that <italic>TWCV</italic><sup>&#x00394; </sup>is attributed from the difference of new <italic>WCV</italic><sub><italic>k </italic></sub>and old <italic>WCV</italic><sub><italic>k </italic></sub>for cluster k. However, <italic>WCV</italic><sub><italic>k </italic></sub>has to be calculated from scratch since <inline-graphic xlink:href="1471-2105-5-172-i18.gif"/> is changed. In this way, TWCV can be updated incrementally as well. Since the calculation of <italic>TWCV </italic>dominates all iterations, our incremental update of <italic>TWCV </italic>will have a better performance when mutation probability is small (which implies a small number of alleles changes). However, if the mutation probability is large, too many alleles change their cluster membership, the maintenance of Z<sub><italic>k </italic></sub><sup>&#x00394; </sup>and <inline-graphic xlink:href="1471-2105-5-172-i19.gif"/> becomes expensive and IGKA becomes inferior to FGKA in performance, as confirmed in the experimental study.</p></sec><sec><title>Hybrid Genetic K-Means Algorithm (HGKA)</title><p>The above discussion presents a dilemma &#x02013; both FGKA and IGKA are likely to outperform each other: when the mutation probability is smaller than some threshold, IGKA outperforms FGKA; otherwise, FGKA outperforms IGKA.</p><p>The key idea of HGKA is to combine the benefits of FGKA and IGKA. However, it is very difficult to derive the threshold value, which is dataset dependant. In addition, the running times of all iterations will vary as solutions converge to the optimum. We propose the following solution: we periodically run one iteration of FGKA followed by one iteration of IGKA while monitoring their running times, and then run the winning algorithm for the following iterations until we reach another competition point.</p><p>It has been proved in [<xref ref-type="bibr" rid="B8">8</xref>] that FGKA will eventually converge to the global optimum. By using the same flowchart and operators, IGKA and HGKA will also converge to the global optimum. We summarize the comparison of various clustering algorithms in Table <xref ref-type="table" rid="T1">1</xref>.</p></sec></sec><sec><title>Availability and requirements</title><p>IGKA algorithm is available at <ext-link ext-link-type="uri" xlink:href="http://database.cs.wayne.edu/proj/FGKA/index.htm"/>. The source code and database scheme are freely distributed to academic users upon request to the authors.</p></sec><sec><title>List of abbreviations</title><p>WCV: Within-Cluster Variation; TWCV: Total Within-Cluster Variation; IGKA: Incremental Genetic K-means Algorithm; FGKA: Fast Genetic K-means Algorithm; HGKA: Hybrid Genetic K-means Algorithm; ORF: Open Reading Frame.</p></sec><sec><title>Authors' contributions</title><p>YL carried out the study and drafted the manuscript. SL and FF designed the algorithms. YD designed the whole project, participated in analyzing gene functional data and wrote part of manuscript. SJB corrected English and helped to interpret the data analysis results.</p></sec></body><back><ack><sec><title>Acknowledgements</title><p>We thank Mr. Jun Chen for helping us in dividing the gene function categories. The project described was supported by NIH grant P20 RR16475 from the BRIN Program of the National Center for Research Resources.</p></sec></ack><ref-list><ref id="B1"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Shamir</surname><given-names>R</given-names></name><name><surname>Sharan</surname><given-names>R</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Jiang T, Smith T, Y. Xu and Zhang MQ</surname></name></person-group><article-title>approaches to clustering gene expression data</article-title><source>Current Topics in Computational Biology</source><year>2001</year><publisher-name>, MIT press</publisher-name></citation></ref><ref id="B2"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Tavazoie</surname><given-names>S</given-names></name><name><surname>Hughes</surname><given-names>JD</given-names></name><name><surname>Campbell</surname><given-names>MJ</given-names></name><name><surname>Cho</surname><given-names>RJ</given-names></name><name><surname>Church</surname><given-names>GM</given-names></name></person-group><article-title>Systematic determination of genetic network architecture</article-title><source>Nat Genet</source><year>1999</year><volume>22</volume><fpage>281</fpage><lpage>285</lpage><pub-id pub-id-type="pmid">10391217</pub-id><pub-id pub-id-type="doi">10.1038/10343</pub-id></citation></ref><ref id="B3"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Bhuyan</surname><given-names>JN</given-names></name><name><surname>Raghavan</surname><given-names>VV</given-names></name><name><surname>Elayavalli</surname><given-names>VK</given-names></name></person-group><source>Genetic algorithm for clustering with an ordered representation: ; San Mateo, CA, USA.</source><year>1991</year></citation></ref><ref id="B4"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hall</surname><given-names>LO</given-names></name><name><surname>B.</surname><given-names>OI</given-names></name><name><surname>Bezdek</surname><given-names>JC</given-names></name></person-group><article-title>Clustering with a genetically optimized approach</article-title><source>IEEE Trans on Evolutionary Computation</source><year>1999</year><volume>3</volume><fpage>103</fpage><lpage>112</lpage><pub-id pub-id-type="doi">10.1109/4235.771164</pub-id></citation></ref><ref id="B5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Maulik</surname><given-names>U</given-names></name><name><surname>Bandyopadhyay</surname><given-names>S</given-names></name></person-group><article-title>Genetic algorithm based clustering technique</article-title><source>Pattern Recognition</source><year>2000</year><fpage>1455</fpage><lpage>1465</lpage><pub-id pub-id-type="doi">10.1016/S0031-3203(99)00137-5</pub-id></citation></ref><ref id="B6"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>D</given-names></name><name><surname>Beltramo</surname><given-names>M</given-names></name></person-group><source>partitioning problems with genetic algorithms: ; San Mateo, CA, USA.</source><year>1991</year></citation></ref><ref id="B7"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Krishna</surname><given-names>K</given-names></name><name><surname>Murty</surname><given-names>M</given-names></name></person-group><article-title>Genetic K-means algorithm</article-title><source>IEEE Transactions on Systems, Man and Cybernetics - Part B: Cybernetics</source><year>1999</year><volume>29</volume><fpage>433</fpage><lpage>439</lpage><pub-id pub-id-type="doi">10.1109/3477.764879</pub-id></citation></ref><ref id="B8"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>Y</given-names></name><name><surname>Lu</surname><given-names>S</given-names></name><name><surname>Fotouhi</surname><given-names>F</given-names></name><name><surname>Deng</surname><given-names>Y</given-names></name><name><surname>Brown</surname><given-names>S</given-names></name></person-group><article-title>FGKA: A Fast Genetic K-means Algorithm: March 2004.</article-title><year>2004</year></citation></ref><ref id="B9"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>Y</given-names></name><name><surname>Lu</surname><given-names>S</given-names></name><name><surname>Fotouhi</surname><given-names>F</given-names></name><name><surname>Deng</surname><given-names>Y</given-names></name><name><surname>Brown</surname><given-names>S</given-names></name></person-group><source>Fast genetic K-means algorithm and its application in gene expression data analysis</source><year>2003</year><publisher-name>Detroit, Wayne State University</publisher-name></citation></ref><ref id="B10"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Iyer</surname><given-names>VR</given-names></name><name><surname>Eisen</surname><given-names>MB</given-names></name><name><surname>Ross</surname><given-names>DT</given-names></name><name><surname>Schuler</surname><given-names>G</given-names></name><name><surname>Moore</surname><given-names>T</given-names></name><name><surname>Lee</surname><given-names>JC</given-names></name><name><surname>Trent</surname><given-names>JM</given-names></name><name><surname>Staudt</surname><given-names>LM</given-names></name><name><surname>Hudson</surname><given-names>JJ</given-names></name><name><surname>Boguski</surname><given-names>MS</given-names></name><name><surname>Lashkari</surname><given-names>D</given-names></name><name><surname>Shalon</surname><given-names>D</given-names></name><name><surname>Botstein</surname><given-names>D</given-names></name><name><surname>Brown</surname><given-names>PO</given-names></name></person-group><article-title>The transcriptional program in the response of human fibroblasts to serum</article-title><source>Science</source><year>1999</year><volume>283</volume><fpage>83</fpage><lpage>87</lpage><pub-id pub-id-type="pmid">9872747</pub-id><pub-id pub-id-type="doi">10.1126/science.283.5398.83</pub-id></citation></ref><ref id="B11"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>de Hoon</surname><given-names>MJ</given-names></name><name><surname>Imoto</surname><given-names>S</given-names></name><name><surname>Nolan</surname><given-names>J</given-names></name><name><surname>Miyano</surname><given-names>S</given-names></name></person-group><article-title>Open source clustering software</article-title><source>Bioinformatics</source><year>2004</year><volume>20</volume><fpage>1453</fpage><lpage>1454</lpage><pub-id pub-id-type="pmid">14871861</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/bth078</pub-id></citation></ref><ref id="B12"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Mewes</surname><given-names>HW</given-names></name><name><surname>Frishman</surname><given-names>D</given-names></name><name><surname>Gruber</surname><given-names>C</given-names></name><name><surname>Geier</surname><given-names>B</given-names></name><name><surname>Haase</surname><given-names>D</given-names></name><name><surname>Kaps</surname><given-names>A</given-names></name><name><surname>Lemcke</surname><given-names>K</given-names></name><name><surname>Mannhaupt</surname><given-names>G</given-names></name><name><surname>Pfeiffer</surname><given-names>F</given-names></name><name><surname>Schuller</surname><given-names>C</given-names></name><name><surname>Stocker</surname><given-names>S</given-names></name><name><surname>Weil</surname><given-names>B</given-names></name></person-group><article-title>MIPS: a database for genomes and protein sequences</article-title><source>Nucleic Acids Res</source><year>2000</year><volume>28</volume><fpage>37</fpage><lpage>40</lpage><pub-id pub-id-type="pmid">10592176</pub-id><pub-id pub-id-type="doi">10.1093/nar/28.1.37</pub-id></citation></ref><ref id="B13"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Goldberg</surname><given-names>D</given-names></name></person-group><source>Genetic Algorithms in Search: Optimization and Machine Learning</source><year>1989</year><publisher-name>MA, Addison-Wesley</publisher-name></citation></ref></ref-list><sec sec-type="display-objects"><title>Figures and Tables</title><fig position="float" id="F1"><label>Figure 1</label><caption><p><italic>The flowchart of IGKA algorithm. </italic>It starts with the initialization phase, which generates the initial population <italic>P</italic><sub>0</sub>. The population in the next generation <italic>P</italic><sub><italic>i </italic>+ 1 </sub>is obtained by applying genetic operators on the current population <italic>P</italic><sub><italic>i</italic></sub>. The evolution takes place until a terminating condition is reached. The selection, the mutation and the K-means operator are sequentially used in IGKA.</p></caption><graphic xlink:href="1471-2105-5-172-1"></graphic></fig><fig position="float" id="F2"><label>Figure 2</label><caption><p><italic>The impacts of mutation probability on time performance for IGKA and FGKA. </italic>The population size is set to 50; the generation size is set to 100. The mutation probability ranges from 0.001 to 0.1 for <italic>fig2data</italic>, and 0.0001 to 0.1 for <italic>chodata</italic>. (A) shows the running time for FGKA and IGKA on <italic>fig2data</italic>. (B) shows the running time for FGKA and IGKA on <italic>chodata</italic>. (C) shows the average and standard error of running time on <italic>fig2data </italic>when the mutation probability is set to 0.001 and 0.005. (D) shows the average and standard error of running time on <italic>chodata </italic>when the mutation probability is set to 0.0001 and 0.0005. When the mutation probability increases, the running time increases accordingly for both algorithms. However, when the mutation probability is smaller than some threshold (0.005 for <italic>fig2data</italic>, and 0.0005 for <italic>chodata</italic>), the IGKA has better performance. It indicates the thresholds vary from one dataset to another. It mainly depends on the number of patterns and the number of features in the data set.</p></caption><graphic xlink:href="1471-2105-5-172-2"></graphic></fig><fig position="float" id="F3"><label>Figure 3</label><caption><p><italic>The impacts of mutation probability on convergence for IGKA and FGKA. </italic>The population size is set to 50; the generation size is set to 100. The mutation probability ranges from 0.001 to 0.1 for <italic>fig2data</italic>, and 0.0001 to 0.1 for <italic>chodata</italic>. (A) shows the convergence with different mutation probability for FGKA and IGKA on <italic>fig2data</italic>. (B) shows the convergence with different mutation probability for FGKA and IGKA on <italic>chodata</italic>. These two algorithms have similar convergence results. When the mutation probability changes in these two data sets, it has little impact on two algorithms during the range that is given in the Figure, except for the case when the mutation probability is too large. It gives an opportunity to choose IGKA with better performance without losing the convergence benefit.</p></caption><graphic xlink:href="1471-2105-5-172-3"></graphic></fig><fig position="float" id="F4"><label>Figure 4</label><caption><p><italic>The performance comparison of IGKA, FGKA and HGKA based on iterations. </italic>The comparison is based on the <italic>chodata </italic>data set, the population number is set to 50 and the mutation probability is set to 0.0001. 100 iterations of three algorithms, IGKA, FGKA and HGKA, are shown in the Figure. The running time for each iteration of FGKA is almost fixed while the running time for IGKA is much higher than FGKA at the beginning and decrease very sharply at late iterations. The HGKA combines the advantage of two algorithms. The turning point in this test case is at iteration 30.</p></caption><graphic xlink:href="1471-2105-5-172-4"></graphic></fig><table-wrap position="float" id="T1"><label>Table 1</label><caption><p>Comparison of different algorithms on performance, convergence and stability. Five apporaches are compared based on time performance, convergence and stability. The K-means algorithm has better time performance than any other genetic algorithms, but it suffers from converging to local optimum and initialization dependent. Among the four genetic clustering approaches, Hybrid approach always has better time performance while FGKA performs well when the mutation probability is big, and IGKA performs well when the mutation probability is small. IGKA and FGKA outperform GKA. The convergence of four genetic algorithms has similar results, and all four are independent from the initialization.</p></caption><table frame="hsides" rules="groups"><thead><tr><td></td><td align="center">K-means</td><td align="center">GKA</td><td align="center">FGKA</td><td align="center">IGKA</td><td align="center">Hybrid</td></tr></thead><tbody><tr><td align="left">Time</td><td align="center">Fastest</td><td align="center">Slow</td><td align="center">Good when the mutation</td><td align="center">Good when the mutation</td><td align="center">Good</td></tr><tr><td align="left">Performance</td><td></td><td></td><td align="center">probability is large</td><td align="center">probability is small</td><td></td></tr><tr><td align="left">Convergence</td><td align="center">Worse</td><td align="center">Good</td><td align="center">Good</td><td align="center">Good</td><td align="center">Good</td></tr><tr><td align="left">Stability</td><td align="center">Unstable</td><td align="center">Stable</td><td align="center">Stable</td><td align="center">Stable</td><td align="center">Stable</td></tr></tbody></table></table-wrap><table-wrap position="float" id="T2"><label>Table 2</label><caption><p>Comparison of different algorithms on TWCV convergence with two data sets. Four algorithms, IGKA, FGKA, K-means and SOM are experimented on the two data set, the <italic>fig2data</italic>, and <italic>chodata</italic>. The TWCVs of IGKA and FGKA algorithm are obtained by averaging 10 individual runs while the generation number is set to 100, the population number is set to 50, the mutation probability is set to 0.005 for <italic>fig2data</italic>, and 0.0005 for <italic>chodata</italic>. The TWCV of K-means algorithm is obtained by averaging 20 individual runs. The TWCV of SOM is obtainedby 8 individual runs with different setting on X and Y dimension. The IGKA and FGKA algorithms have better TWCV convergence than the K-means and SOM.</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left">Algorithms</td><td align="center">Fig2data</td><td align="center">Chodata</td></tr></thead><tbody><tr><td align="left">IGKA (Average of 10 individual runs with generation 100, population 50, mutation probability 0.005 in <italic>fig2data</italic>, and 0.0005 in <italic>chodata</italic>)</td><td align="left">4991.53889</td><td align="left">16995.7</td></tr><tr><td align="left">FGKA (Average of 10 individual runs with generation 100, population 50, mutation probability 0.005 in <italic>fig2data</italic>, and 0.0005 in <italic>chodata</italic>)</td><td align="left">4992.13889</td><td align="left">16995.4</td></tr><tr><td align="left">K-means (Average of 20 individual runs)</td><td align="left">5154.21434</td><td align="left">17374.6758</td></tr><tr><td align="left">SOM (Average of 8 individual runs with different setting)</td><td align="left">24805.3661</td><td align="left">21660.9049</td></tr></tbody></table></table-wrap><table-wrap position="float" id="T3"><label>Table 3</label><caption><p>Distribution of ORF function categories in the clusters. Chodata set was clustered using IGKA algorithm. We identified the gene distribution of different functional categories into different clusters. The function categories were divided according to MIPS (Mewes et al., 2000). The total number of ORFs in each function category was indicated in parentheses. The cluster number to which the genes were grouped is denoted as "Cluster" column. The ORF number in each cluster is denoted as "Total". The ORF number within each functional category is denoted as "Function ORFs". The percentage of the ORF number within functional category of each cluster in the total ORF number of each cluster is denoted as "Percentage (%)".</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left">Cluster</td><td align="left">MIPS functional category</td><td align="left">Total</td><td align="left">Function ORFs</td><td align="left">Percentage(%)</td></tr></thead><tbody><tr><td align="left">1</td><td align="left">Mitotic cell cycle and cycle control(352)</td><td align="left">86</td><td align="left">24</td><td align="left">27.9</td></tr><tr><td></td><td align="left">Budding, cell polarity, filament form(170)</td><td></td><td align="left">8</td><td align="left">9.3</td></tr><tr><td align="left">3</td><td align="left">Organization of mitochondrion(366)</td><td align="left">156</td><td align="left">111</td><td align="left">71.2</td></tr><tr><td></td><td align="left">Respiration(88)</td><td></td><td align="left">10</td><td align="left">6.4</td></tr><tr><td></td><td align="left">Nitrogen and sulpur metabolism(67)</td><td></td><td align="left">9</td><td align="left">5.6</td></tr><tr><td align="left">16</td><td align="left">Organization of nucleus(774)</td><td align="left">133</td><td align="left">50</td><td align="left">37.6</td></tr><tr><td align="left">17</td><td align="left">Ribosome biogenesis(215)</td><td align="left">88</td><td align="left">50</td><td align="left">56.8</td></tr><tr><td></td><td align="left">Organization of cytoplasm(554)</td><td></td><td align="left">31</td><td align="left">35.2</td></tr><tr><td align="left">18</td><td align="left">Organization of mitochondrion(366)</td><td align="left">184</td><td align="left">105</td><td align="left">57.1</td></tr><tr><td align="left">25</td><td align="left">DNA synthesis and replication(94)</td><td align="left">164</td><td align="left">23</td><td align="left">14</td></tr><tr><td></td><td align="left">DNA recombination and DNA repair(153)</td><td></td><td align="left">11</td><td align="left">6.7</td></tr><tr><td></td><td align="left">Lipid and fatty isoprenoid metabolism(213)</td><td></td><td align="left">9</td><td align="left">5.5</td></tr><tr><td align="left">29</td><td align="left">Organization of nucleus chromosome(44)</td><td align="left">93</td><td align="left">14</td><td align="left">15</td></tr><tr><td></td><td align="left">Amino acid metabolism(204)</td><td></td><td align="left">12</td><td align="left">12.9</td></tr><tr><td align="left">30</td><td align="left">TCA pathway or Krebs cycle(25)</td><td align="left">92</td><td align="left">7</td><td align="left">7.6</td></tr><tr><td></td><td align="left">C-compound, carbohydrate metabolism(415)</td><td></td><td align="left">14</td><td align="left">15.2</td></tr></tbody></table></table-wrap></sec></back></article>



