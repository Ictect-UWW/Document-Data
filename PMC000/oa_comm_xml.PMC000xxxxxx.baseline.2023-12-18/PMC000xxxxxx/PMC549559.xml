<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id><journal-title>BMC Bioinformatics</journal-title><issn pub-type="epub">1471-2105</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">15705208</article-id><article-id pub-id-type="pmc">PMC549559</article-id><article-id pub-id-type="publisher-id">1471-2105-6-27</article-id><article-id pub-id-type="doi">10.1186/1471-2105-6-27</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>A statistical approach for array CGH data analysis</article-title></title-group><contrib-group><contrib id="A1" corresp="yes" contrib-type="author"><name><surname>Picard</surname><given-names>Franck</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>picard@inapg.fr</email></contrib><contrib id="A2" corresp="yes" contrib-type="author"><name><surname>Robin</surname><given-names>Stephane</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>robin@inapg.fr</email></contrib><contrib id="A3" contrib-type="author"><name><surname>Lavielle</surname><given-names>Marc</given-names></name><xref ref-type="aff" rid="I2">2</xref><email>lavielle@math.u-psud.fr</email></contrib><contrib id="A4" contrib-type="author"><name><surname>Vaisse</surname><given-names>Christian</given-names></name><xref ref-type="aff" rid="I3">3</xref><email>vaisse@medicine.ucsf.edu</email></contrib><contrib id="A5" contrib-type="author"><name><surname>Daudin</surname><given-names>Jean-Jacques</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>daudin@inapg.fr</email></contrib></contrib-group><aff id="I1"><label>1</label>Institut National Agronomique Paris-Grignon, UMR INAPG/ENGREF/INRA MIA 518, Paris, France</aff><aff id="I2"><label>2</label>Universit&#x000e9; Paris Sud, Equipe Probabilit&#x000e9;s, Statistique et Mod&#x000e9;lisation, Orsay, France</aff><aff id="I3"><label>3</label>University of California San Francisco, Diabetes Center, San Francisco, USA</aff><pub-date pub-type="collection"><year>2005</year></pub-date><pub-date pub-type="epub"><day>11</day><month>2</month><year>2005</year></pub-date><volume>6</volume><fpage>27</fpage><lpage>27</lpage><ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1471-2105/6/27"/><history><date date-type="received"><day>18</day><month>8</month><year>2004</year></date><date date-type="accepted"><day>11</day><month>2</month><year>2005</year></date></history><copyright-statement>Copyright &#x000a9; 2005 Picard et al; licensee BioMed Central Ltd.</copyright-statement><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0"/>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</p></license><abstract><sec><title>Background</title><p>Microarray-CGH experiments are used to detect and map chromosomal imbalances, by hybridizing targets of genomic DNA from a test and a reference sample to sequences immobilized on a slide. These probes are genomic DNA sequences (BACs) that are mapped on the genome. The signal has a spatial coherence that can be handled by specific statistical tools. Segmentation methods seem to be a natural framework for this purpose. A CGH profile can be viewed as a succession of segments that represent homogeneous regions in the genome whose BACs share the same relative copy number on average. We model a CGH profile by a random Gaussian process whose distribution parameters are affected by abrupt changes at unknown coordinates. Two major problems arise : to determine which parameters are affected by the abrupt changes (the mean and the variance, or the mean only), and the selection of the number of segments in the profile.</p></sec><sec><title>Results</title><p>We demonstrate that existing methods for estimating the number of segments are not well adapted in the case of array CGH data, and we propose an adaptive criterion that detects previously mapped chromosomal aberrations. The performances of this method are discussed based on simulations and publicly available data sets. Then we discuss the choice of modeling for array CGH data and show that the model with a homogeneous variance is adapted to this context.</p></sec><sec><title>Conclusions</title><p>Array CGH data analysis is an emerging field that needs appropriate statistical tools. Process segmentation and model selection provide a theoretical framework that allows precise biological interpretations. Adaptive methods for model selection give promising results concerning the estimation of the number of altered regions on the genome.</p></sec></abstract></article-meta></front><body><sec><title>Background</title><p>Chromosomal aberrations often occur in solid tumors: tumor suppressor genes may be inactivated by physical deletion, and oncogenes activated via duplication in the genome. Gene dosage effect has become particularly important in the understanding of human solid tumor genesis and progression, and has also been associated with other diseases such as mental retardation [<xref ref-type="bibr" rid="B1">1</xref>,<xref ref-type="bibr" rid="B2">2</xref>]. Chromosomal aberrations can be studied using many different techniques, such as Comparative Genomic Hybridization (CGH), Fluorescence in Situ Hybridization (FISH), and Representational Difference Analysis (RDA). Although chromosome CGH has become a standard method for cytogenetic studies, technical limitations restrict its usefulness as a comprehensive screening tool [<xref ref-type="bibr" rid="B3">3</xref>]. Recently, the resolution of Comparative Genomic Hybridizations has been greatly improved using microarray technology [<xref ref-type="bibr" rid="B4">4</xref>,<xref ref-type="bibr" rid="B5">5</xref>].</p><p>The purpose of array-based Comparative Genomic Hybridization (array CGH) is to detect and map chromosomal aberrations, on a genomic scale, in a single experiment. Since chromosomal copy numbers can not be measured directly, two samples of genomic DNA (referred to as the reference and test DNAs) are differentially labelled with fluorescent dyes and competitively hybridized to known mapped sequences (referred to as BACs) that are immobilized on a slide. Subsequently, the ratio of the intensities of the two fluorochromes is computed and a CGH profile is constituted for each chromosome when the log<sub>2 </sub>of fluorescence ratios are ranked and plotted according to the physical position of their corresponding BACs on the genome [<xref ref-type="bibr" rid="B6">6</xref>]. Different methods and packages have been proposed for the visualization of array CGH data [<xref ref-type="bibr" rid="B7">7</xref>,<xref ref-type="bibr" rid="B8">8</xref>].</p><p>Each profile can be viewed as a succession of "segments" that represent homogeneous regions in the genome whose BACs share the same relative copy number on average. Array CGH data are normalized with a median set to log<sub>2</sub>(ratio) = 0 for regions of no change, segments with positive means represent duplicated regions in the test sample genome, and segments with negative means represent deleted regions. Even if the underlying biological process is discrete (counting of relative copy numbers of DNA sequences), the signal under study is viewed as being continuous, because the quantification is based on fluorescence measurements, and because the possible values for chromosomal copy numbers in the test sample may vary considerably, especially in the case of clinical tumor samples that present mixtures of tissues of different natures.</p><p>Two main statistical approches have been considered for the analysis of array CGH data. The first has focused many attentions, and is based on segmentation methods where the purpose is to locate segments of biological interest [<xref ref-type="bibr" rid="B7">7</xref>,<xref ref-type="bibr" rid="B9">9</xref>-<xref ref-type="bibr" rid="B11">11</xref>]. A second approach is based on Hidden Markov Models (aCGH R-package [<xref ref-type="bibr" rid="B12">12</xref>]), where the purpose is to cluster individual data points into a finite number of hidden groups. Our approach can be put into the first category. Segmentation methods seem to be a natural framework to handle the spatial coherence of the data on the genome that is specific to array CGH. In this context the signal provided by array CGH data is supposed to be a realization of a Gaussian process whose parameters are affected by an unknown number of abrupt changes at unknown locations on the genome. Two models can be considered, according to the characteristics of the signal that is affected by the changes: it can be either the mean of the signal [<xref ref-type="bibr" rid="B7">7</xref>,<xref ref-type="bibr" rid="B10">10</xref>,<xref ref-type="bibr" rid="B11">11</xref>] or the mean and the variance [<xref ref-type="bibr" rid="B9">9</xref>]. Since the choice of modeling is crucial in any interpretation of a segmented CGH profile, we provide guidelines for this choice in the discussion. Two major issues arise in break-points detection studies: the localization of the segments on the genome, and the estimation of the number of segments. The first point has lead to the definition of many algorithms and packages: segmentation algorithms [<xref ref-type="bibr" rid="B9">9</xref>,<xref ref-type="bibr" rid="B10">10</xref>] and smoothing algorithms [<xref ref-type="bibr" rid="B11">11</xref>] where the break-points are defined with a <italic>posterior </italic>empirical criterion. These methods are defined by a criterion to optimize and an algorithm of optimization. Different criteria have been proposed: the likelihood criterion [<xref ref-type="bibr" rid="B9">9</xref>,<xref ref-type="bibr" rid="B11">11</xref>], the least-squares criterion [<xref ref-type="bibr" rid="B7">7</xref>], partial sums [<xref ref-type="bibr" rid="B10">10</xref>], and algorithms of optimization are based on genetic algorithms [<xref ref-type="bibr" rid="B9">9</xref>], dynamic programing [<xref ref-type="bibr" rid="B7">7</xref>], binary segmentation (DNAcopy R-package [<xref ref-type="bibr" rid="B10">10</xref>]) and adaptive weigths smoothing (GLAD R-package [<xref ref-type="bibr" rid="B11">11</xref>]). Since many criteria and algorithms have been proposed, one important question is the resulting statistical properties of the break-point estimators they provide. Note that smoothing techniques do not provide estimators of the break-point coordinates, since the primary goal of the underlying model is to smooth the data, and break-points are not parameters of the model (in this case, they are defined after the optimization of the criterion [<xref ref-type="bibr" rid="B11">11</xref>]). Here we consider the likelihood criterion and we use dynamic programming that provides a global optimum solution, contrary to genetic algorithms [<xref ref-type="bibr" rid="B9">9</xref>], in a reasonable computational time.</p><p>As for the estimation of the number of segments, the existing articles have not defined any statistical criterion adapted to the case of process segmentation. This problem is theoretically complex, and has lead to <italic>ad hoc </italic>procedures [<xref ref-type="bibr" rid="B9">9</xref>-<xref ref-type="bibr" rid="B11">11</xref>]. Since the purpose of array CGH experiments is to discover biological events, the estimation of the number of segments remains central. This problem can be handled in the more general context of model selection. In the discussion we explain why classical criteria based on penalized likelihoods are not valid for break-points detection. Criteria such as the Akaike Information Criterion (AIC) and the Bayes Information Criterion (BIC) lead to an overestimation of the number of segments. For this reason, an arbitrary penalty constant can be chosen in order to select a lower number of segments in the profile [<xref ref-type="bibr" rid="B9">9</xref>]. We propose a new procedure to estimate the number of segments, choosing the penalty constant adaptively to the data. We explain the construction of such penalty, and its performances are compared to other criteria in the Results Section, based on simulation studies and on publicly available data sets. Put together, we propose a methodology that considers a simple modeling, a fast and effective algorithm of optimization and that takes advantages of the statistical properties of the maximum likelihood. Our procedure has been implemented on MATLAB Software and is freely available <ext-link ext-link-type="uri" xlink:href="http://www.inapg.fr/ens_rech/mathinfo/recherche/mathematique/outil.html"/>.</p></sec><sec><title>Results</title><sec><title>Comparison of model selection criteria</title><p>To show the importance of the choice of the model selection criterion on simple data, we use the results of a single experiment performed on fibroblast cell lines (see the Materials Section), with one known chromosomal aberration. Figure <xref ref-type="fig" rid="F1">1</xref> shows the resulting segmentations when using the Bayesian Information Criterion, and our criterion. BIC leads to an oversegmented profile that is not interpretable in terms of relative copy numbers. Our procedure estimates the correct number of segments <inline-graphic xlink:href="1471-2105-6-27-i1.gif"/>. This example shows the practical consequences of the use of theoretically unappropriated criteria. This point constitutes the main purpose of the discussion (see the Discussion Section).</p><p>Numerical simulations are performed to study the sensitivity of different criteria to varying amounts of noise. The simulation design is described in the Methods Section. We compare four different criteria: the Bayesian Information Criterion, two previously described criteria [<xref ref-type="bibr" rid="B9">9</xref>,<xref ref-type="bibr" rid="B13">13</xref>], and the criterion we propose, in their ability to estimate the correct number of segments. Two configurations were tested, for a true number of segments <italic>K</italic>* = 5. In the first situation, the segments are regularly spaced with a jump of the mean of 1 (Figure <xref ref-type="fig" rid="F3">3</xref>), whereas in the second case, the segments are not regularly spaced and the differences of means vary between <italic>d </italic>= 2 and <italic>d </italic>= 0.5 (Figure <xref ref-type="fig" rid="F4">4</xref>). The first result is that BIC overestimates the number of segments, whatever the noise and the configuration (Figure <xref ref-type="fig" rid="F2">2</xref>). On the contrary, previously described criteria [<xref ref-type="bibr" rid="B9">9</xref>,<xref ref-type="bibr" rid="B13">13</xref>] tend to underestimate the number of segments when the noise increases, whatever the configuration. These results suggest that those two criteria "prefer" to detect no break-point as the noise increases, leading to possible false negative results.</p><p>The behavior of the criterion we propose is different. It seems to be more robust to the noise, as it will give a number of segments that is close to the true number. In particular, the irregular configuration presents a segment of small size (5 points at <italic>t </italic>= 80) that could be interesting to detect in the case of array CGH profile (a putative gained region for instance). Since the previously described criteria [<xref ref-type="bibr" rid="B9">9</xref>,<xref ref-type="bibr" rid="B13">13</xref>] tend to underestimate the number of segments, this particular region would not be detected. On the contrary, the adaptive criterion will be able to detect it, even if the noise is important, since it selects a constant number of segments close to the true number whatever the noise. These simulation examples perfectly illustrate the capacity of an adaptive criterion to find a reasonable number of segments even in configurations where the profile is not very separated.</p><p>We also compare the performance of our criterion and of the arbitrary criterion [<xref ref-type="bibr" rid="B9">9</xref>] on breast cancer cell lines. Figure <xref ref-type="fig" rid="F5">5</xref> shows the resulting segmentations on chromosomes 9 and 10 of the Bt474 cell line (see the Materials Section for further description). As previously mentioned, the arbitrary criterion [<xref ref-type="bibr" rid="B9">9</xref>] selects a lower number of segments compared to the adaptive criterion, and we note that interesting regions are not detected (a putative outlier on chromosome 9 at 1.58 Mb and a putative deleted region on chromosome 10 at 1.76 Mb). Since the aim of array CGH experiments is to discover unknown chromosomal aberrations, the use of an adaptive criterion seems more appropriate in this context since it allows the identification of regions that seem biologically relevent.</p><p>The second simulation-based result concerns the ability of dynamic programming to locate the break-points at the correct coordinate, given different amounts of noise (Figures <xref ref-type="fig" rid="F3">3</xref> and <xref ref-type="fig" rid="F4">4</xref>). In the regular configuration (Figure <xref ref-type="fig" rid="F3">3</xref>), simulation results show that dynamic programming perfectly localizes the break-points when the variability of the noise <italic>&#x003c3;</italic><sup>2 </sup>is low regarding the jump <italic>d </italic>of the mean. If <italic>d</italic>/<italic>&#x003c3; </italic>= 10 the estimated probability to localize the break-points at the correct coordinate is 1, and this probability deacreases with the noise (probability close to 0.65 for <italic>d</italic>/<italic>&#x003c3; </italic>= 2 and 0.25 for <italic>d</italic>/<italic>&#x003c3; </italic>= 1). The effect of additional noise is to widden the zone of estimation, but the estimated break-points remain close to the true break-points. If the true break-point is located at <italic>t</italic>*, the estimated break-point stays in the interval <italic>t</italic>* &#x000b1; 3. In the irregular configuration, additional noise has similar effects on the break-point's positioning, but the probability to correctly estimate a break-point depends on the jump of the mean between two segments. In the irregular case, Figure <xref ref-type="fig" rid="F4">4</xref>, at position <italic>t </italic>= 40 the difference of mean is <italic>d </italic>= 2, and the probability to locate the break-point at the true coordinate is higher than 0.65 for any additional noise. On the contrary, at position <italic>t </italic>= 85 where the different of mean equals <italic>d </italic>= 0.5 the probability to correctly locate the break-point decreases dramatically with the noise (probability 1 for <italic>&#x003c3; </italic>= 0.1 and probability 0.25 for <italic>&#x003c3; </italic>= 0.5). This means that dynamic programming is sensitive to small segments that present little differences in the mean regarding the noise. Nevertheless, the example on the real data set presented in Figure <xref ref-type="fig" rid="F5">5</xref> shows that using an adaptive criterion with dynamic programming allows for the identification of small regions of putative biological interest as mentioned above. Put together, these simulation results show that the adaptive method selects the good number of segments even in the presence of important noise, and that when this number is selected, dynamic programming is able to correctly localize the break-point. In addition to its ability to locate precisely the break-points, it is important to notice that dynamic programming provides a global optimum of the likelihood that is required for any model selection procedure to select the number of segments, compared to genetic algorithms [<xref ref-type="bibr" rid="B9">9</xref>].</p></sec><sec><title>Segmentation models in the Gaussian framework</title><p>The CGH profile is supposed to be a Gaussian signal. In a segmentation framework, two types of changes can be considered: changes in the mean and the variance of the signal, or changes in the mean only. Let us define model <inline-graphic xlink:href="1471-2105-6-27-i2.gif"/> where each segment has a specific mean and variance [<xref ref-type="bibr" rid="B9">9</xref>], and model <inline-graphic xlink:href="1471-2105-6-27-i3.gif"/>, where the variance is common between segments [<xref ref-type="bibr" rid="B7">7</xref>].</p><p>Since both models can be used, it is important to explore their behavior in order to know which model is the best adapted to the special case of array CGH data. We use clinical data obtained from primary dissected tumors of colorectal cancers (see the Materials Section for further details). Figure <xref ref-type="fig" rid="F6">6</xref> presents the results of segmentations for three experiments obtained with the two models <inline-graphic xlink:href="1471-2105-6-27-i2.gif"/> and <inline-graphic xlink:href="1471-2105-6-27-i3.gif"/> when our criterion is used to estimate the number of segments. The main result of this comparison is that the number of segments is higher using model <inline-graphic xlink:href="1471-2105-6-27-i3.gif"/> compared to model <inline-graphic xlink:href="1471-2105-6-27-i2.gif"/>. This behavior of model <inline-graphic xlink:href="1471-2105-6-27-i3.gif"/> could be interpreted as a trend to divide large segments into smaller parts, in order to maintain the variance homogeneous between segments. This leads to a more segmented profile, maybe more precise, but that may be more difficult to interpret in terms of relative copy numbers. Nevertheless, as model <inline-graphic xlink:href="1471-2105-6-27-i3.gif"/> allows the exploration of segments with one observation, it will be more efficient for the identification of outliers, as shown in Figure <xref ref-type="fig" rid="F6">6</xref> (experiment X411, model <inline-graphic xlink:href="1471-2105-6-27-i3.gif"/>, point at 100 Mb).</p></sec></sec><sec><title>Discussion</title><p>The definition of an appropriate penalized criterion has been an issue for previous works using segmentation methods for array CGH data analysis [<xref ref-type="bibr" rid="B8">8</xref>,<xref ref-type="bibr" rid="B9">9</xref>,<xref ref-type="bibr" rid="B11">11</xref>]. In this section, we explain the specificity of model selection in the case of process segmentation, in order to give further justification to the inefficiency of classical criteria to select the number of segments, as shown in the Results Section.</p><sec><title>Estimating the number of segments via penalized likelihood</title><p>When the number of segments is known, the maximization of the log-likelihood <inline-graphic xlink:href="1471-2105-6-27-i4.gif"/> gives the best segmentation with <italic>K </italic>segments (see the Methods Section). In real situations this number is unknown, and one has to choose among many possible segmentations. The maximum of the log-likelihood <inline-graphic xlink:href="1471-2105-6-27-i5.gif"/> can be viewed as a quality measurement of the fit to the data of the model with <italic>K </italic>segments, and will be maximal when each data point is in its own segment. Therefore selecting the number of segments only based on the likelihood criterion would lead to overfitting. Furthermore, the number of parameters to estimate is proportional to the number of segments, and a too large number of segments would lead to a large estimation error. A penalized version of the likelihood is used as a trade-off between a good adjustement and a reasonable number of parameters to estimate. It is noted</p><p><inline-graphic xlink:href="1471-2105-6-27-i6.gif"/></p><p>where <italic>pen</italic>(<italic>K</italic>) is a penalty function that increases with the number of segments, and <italic>&#x003b2; </italic>is a constant of penalization. The estimated number of segments is such as :</p><p><inline-graphic xlink:href="1471-2105-6-27-i7.gif"/></p><p>It is crucial to notice that the criterion which is penalized should provide the best partition of <italic>K</italic>-dimensional, <italic>ie </italic>for a fixed <italic>K </italic>the criterion has to be globally maximized to ensure convergence of the break-point estimators to the true break-points [<xref ref-type="bibr" rid="B14">14</xref>]. This optimum is provided by dynamic programming, but not by other algorithms [<xref ref-type="bibr" rid="B9">9</xref>,<xref ref-type="bibr" rid="B10">10</xref>].</p></sec><sec><title>Choice of the penalty function and constant</title><p>Classical penalized likelihoods use the number of independent continuous parameters to be estimated as a penalty function. Even though those criteria are widely used in the context of model selection, theoretical considerations suggest that they are not appropriate in the context of an exhaustive search for abrupt changes.</p><p>Let us focus on the penalty function in a first step. Table <xref ref-type="table" rid="T1">1</xref> provides a summary of different penalties. For classical information criteria, such as the Akaike Information Criterion and the Bayes Information Criterion, the penalty function equals to 2<italic>K </italic>(<italic>K </italic>means and <italic>K </italic>variances) for a heteroscedastic model with <italic>K </italic>segments. Penalized criteria have already been used in the context of array CGH data analysis to estimate the number of segments [<xref ref-type="bibr" rid="B9">9</xref>]. In addition to the 2<italic>K </italic>parameters, they implicitly consider that the break-points are also continuous parameters, leading to a new penalty function <italic>pen</italic>(<italic>K</italic>) = 3<italic>K </italic>- 1, which considers <italic>K </italic>- 1 break-points. Nevertheless, the characteristic of break-point detection models lies in the mixture of continuous parameters and discrete parameters that can not be counted as continuous parameters, since the number of possible configurations for <italic>K </italic>segments is finite and equals <inline-graphic xlink:href="1471-2105-6-27-i8.gif"/> (with <italic>n </italic>the total number of points) [<xref ref-type="bibr" rid="B13">13</xref>].</p><p>This leads to the definition of a new penalty function adapted to the special context of the exhaustive search of abrupt changes. This function (table <xref ref-type="table" rid="T1">1</xref>) is proportional to the number of continuous parameters, but is also proportional to a new term in <inline-graphic xlink:href="1471-2105-6-27-i11.gif"/> that takes the complexity of the visited configurations into account. It is written <italic>pen</italic>(<italic>K</italic>) = 2<italic>K</italic>(<italic>c</italic><sub>1 </sub>+ <italic>c</italic><sub>2</sub><inline-graphic xlink:href="1471-2105-6-27-i11.gif"/>), where <italic>c</italic><sub>1 </sub>and <italic>c</italic><sub>2 </sub>are constant coefficients that have to be calibrated using numerical simulations. Since AIC and BIC and the criterion proposed in [<xref ref-type="bibr" rid="B9">9</xref>] do not consider the complexity of the visited models, they select a too high number of segments. The second term of the penalty is the penalty constant <italic>&#x003b2;</italic>. This term is constant in the case of AIC and BIC (<italic>&#x003b2; </italic>= 1, <italic>&#x003b2; </italic>= <inline-graphic xlink:href="1471-2105-6-27-i9.gif"/>, respectively), and contributes to the oversegmentation as mentioned above. This can lead to an empirical choice for the constant, in order to obtain expected results based on <italic>a priori </italic>knowledge. For this reason, an arbitrary penalty constant can be chosen for the procedure to select a reasonable number of segments (<italic>&#x003b2; </italic>= 10/3 in [<xref ref-type="bibr" rid="B9">9</xref>]). Instead of an arbitrary choice for this constant, <italic>&#x003b2; </italic>can be adaptively chosen to the data [<xref ref-type="bibr" rid="B13">13</xref>,<xref ref-type="bibr" rid="B14">14</xref>]. Furthermore, when the number of segments is small with respect to the number of data points (which is the case in CGH data analysis), the log-term can be considered as a constant [<xref ref-type="bibr" rid="B14">14</xref>]. The author rather suggests to use the penalty function <italic>pen</italic>(<italic>K</italic>) = 2<italic>K </italic>and to define an automatic procedure to choose the constant of penalization <italic>&#x003b2; </italic>adaptively. We explain the estimation procedure for the penalty constant in the Methods Section.</p><p>The power of adaptive methods for model selection lies in the definition of a penalty that is not universal (such as in the case of AIC and BIC). This means that the dimension of the model is estimated adaptively to the data. The efficiency of such method has been shown on simulated data as well as on experimental results (Results Section), and adaptive model selection criteria seem to be very appropriate for array CGH data analysis.</p></sec><sec><title>Choice of modelling for array CGH data</title><p>Since the choice of modeling affects the resulting segmentation, it is crucial to provide guidelines for their use. This can be done with the interpretation of the statistical models in terms of their biological meaning. The difference between model <inline-graphic xlink:href="1471-2105-6-27-i2.gif"/> and <inline-graphic xlink:href="1471-2105-6-27-i3.gif"/> concerns the modeling of the variance: model <inline-graphic xlink:href="1471-2105-6-27-i2.gif"/> assumes that the variability of the signal is organized along the chromosome, whereas model <inline-graphic xlink:href="1471-2105-6-27-i3.gif"/> specifies that the variance is constant. Since it has been shown that the vast majority of clones all had the same response to copy number changes in the aneuploid cell lines [<xref ref-type="bibr" rid="B6">6</xref>], the use of model <inline-graphic xlink:href="1471-2105-6-27-i3.gif"/> would be justified regarding this experimental argument.</p><p>Outliers seem to be a major concern in microarray CGH data analysis. For instance, if only one BAC is altered whereas its neighbors are not, the conclusion could be either that it is biologically relevant, or that the signal is due to technical artefacts. Replications are crucial in this situation, as well as secondary validations. An other possibility could be that the BAC is misannotated: if the ratio is plotted at the wrong coordinate on the genome, it will appear as an outlier, when it is not. The importance of outlier identification is another argument in favor of model <inline-graphic xlink:href="1471-2105-6-27-i3.gif"/>, that can detect changes for one data point, whereas with model <inline-graphic xlink:href="1471-2105-6-27-i2.gif"/> outliers would belong to segments with higher variance.</p><p>It has to be noted that classical models used in segmentation methods assume the independence of the data. This may be a reasonnable assumption for BAC arrays whose genome representation is approximately 1 BAC every 1.4 Mb [<xref ref-type="bibr" rid="B6">6</xref>]. Nevertheless, a new generation of arrays now provides a tiling resolution of the genome [<xref ref-type="bibr" rid="B15">15</xref>]. The overlapping of successive BACs could lead to statistical correlations that will require developments of new segmentation models for correlated processes.</p></sec></sec><sec><title>Conclusions</title><p>Microarray CGH currently constitutes the most powerful method to detect gain or loss of genetic material on a genomic scale. To date, applications have been mainly restricted to cancer research, but the emerging potentialities of this technique have also been applied to the study of congenital and acquired diseases. As expression profile experiments require careful statistical analysis before any biological expertise, CGH microarray experiments will require specific statistical tools to handle experimental variability, and to consider the specificity of the the studied biological phenomena. We introduced a statistical method for the analysis of CGH microarray data that models the abrupt changes in the relative copy number ratio between a test DNA and a reference DNA. We discuss the effects of different modelings that can be used in segmentation methods, and suggest the use of a model that considers the homogeneity of the signal variability based on experimental arguments and regarding the specificity of array CGH data.</p><p>The main theoretical issue of array CGH data analysis lies in the estimation of the number of segments that requires the definition of appropriate penalty function and constant. We define a new procedure that estimates the number of segments adaptively to the data. This method selects the number of segments with high accuracy compared to previously mapped aberrations, and seems to be more efficient compared to others proposed to date. The use of dynamic programming remains central to localizing the break-points, and the simulation results show that when the good number of segments are selected, the algorithm localizes the break-points very close to the truth. Assessing the number of segments in a model is theoretically complex, and requires the definition of a precise model of inference. To that extent, microarray CGH analysis not only requires computational approaches, but also a careful statistical methodology.</p></sec><sec sec-type="methods"><title>Methods</title><sec sec-type="materials"><title>Materials</title><p>We briefly present the data we used in this article. The first data we use in the Results Section consist of a single experiment on fibroblast cell lines (Coriell Cell lines) whose chromosomal aberrations have been previously mapped. Those defaults concern partial or whole chromosome aneuploidy. This data have been previously used by other authors [<xref ref-type="bibr" rid="B10">10</xref>]. The second group of data used in the Results section is described in [<xref ref-type="bibr" rid="B6">6</xref>]. A test genome of Bt474 cell lines is compared to a normal reference male genome. The last data set used is described in [<xref ref-type="bibr" rid="B16">16</xref>] and consists of 125 primary colorectal tumors that were surgically dissected and frozen. The arrays used for these analysis are BAC arrays described in [<xref ref-type="bibr" rid="B6">6</xref>].</p></sec><sec><title>Models and Likelihoods</title><p>In this section, we define the models <inline-graphic xlink:href="1471-2105-6-27-i2.gif"/> and <inline-graphic xlink:href="1471-2105-6-27-i3.gif"/>. Let us consider a CGH profile, and note <italic>y</italic><sub><italic>t</italic></sub>, the log<sub>2</sub>-ratio of the intensities for the <italic>t</italic><sup><italic>th </italic></sup>BAC on the genome. Precisely <italic>y</italic><sub><italic>t </italic></sub>represents the average signal obtained from the replicated spots on the slide. BACs are the basic units in our model, and are ordered according to their physical position. We suppose that the <italic>y</italic><sub><italic>t </italic></sub>are the realizations of independent random variables {<italic>Y</italic><sub><italic>t</italic></sub>}<sub><italic>t </italic>= 1...<italic>n</italic></sub>, with Gaussian distributions <inline-graphic xlink:href="1471-2105-6-27-i12.gif"/>. We assume that <italic>K </italic>- 1 changes affect the parameters of the distribution of the <italic>Ys</italic>, at unknown coordinates (<italic>t</italic><sub>0</sub>, <italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub>,...,<italic>t</italic><sub><italic>K </italic>- 1</sub>, <italic>t</italic><sub><italic>K</italic></sub>) with convention <italic>t</italic><sub>0 </sub>= 1 and <italic>t</italic><sub><italic>K </italic></sub>= <italic>n</italic>, and that the parameters of the <italic>Ys </italic>distributions are constant between two changes:</p><p><inline-graphic xlink:href="1471-2105-6-27-i13.gif"/></p><p>where <italic>&#x003bc;</italic><sub><italic>k </italic></sub>is the mean of the <italic>k</italic><sup><italic>th </italic></sup>segment. Model <inline-graphic xlink:href="1471-2105-6-27-i2.gif"/> specifies that the variance is segment-specific (<inline-graphic xlink:href="1471-2105-6-27-i14.gif"/>), whereas <inline-graphic xlink:href="1471-2105-6-27-i3.gif"/> considers that the variance is common between segments (<italic>&#x003c3;</italic><sup>2</sup>). Since BACs are supposed to be independent, the log-likelihood can be decomposed into a sum of "local" likelihoods, calculated on each segments: <inline-graphic xlink:href="1471-2105-6-27-i15.gif"/>, with</p><p><inline-graphic xlink:href="1471-2105-6-27-i16.gif"/></p></sec><sec><title>Estimation of the segment's mean and variance</title><p>Given the number of segments <italic>K </italic>and the segments' coordinates <italic>(t</italic><sub>0</sub>, <italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub>,...,<italic>t</italic><sub><italic>K</italic>-1</sub>, <italic>t</italic><sub><italic>K</italic></sub>), we estimate the mean and the variance for each segment using maximum likelihood :</p><p><inline-graphic xlink:href="1471-2105-6-27-i17.gif"/></p><p>If the variance of the segments is homogeneous, its estimator is given by:</p><p><inline-graphic xlink:href="1471-2105-6-27-i18.gif"/></p><p>Notice that when the segment coordinates are known, the estimation of the mean and variance for each segment is straightforward. Then, the key problem is to estimate <italic>K </italic>and (<italic>t</italic><sub>0</sub>, <italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub>,...,<italic>t</italic><sub><italic>K </italic>- 1</sub>, <italic>t</italic><sub><italic>K</italic></sub>). We will proceed in two steps: in the first step, we will consider that the number of segments is known, and the problem will be to estimate the <italic>t</italic><sub><italic>k</italic></sub>s, that is, to find the best partition of a set of <italic>n </italic>individuals into <italic>K </italic>segments. In the second step, we will estimate the number of segments, using a penalized version of the likelihood.</p></sec><sec><title>A segmentation algorithm when the number of segments is known</title><p>When the number of segments <italic>K </italic>is known, the problem is to find the best partition of {1,...,<italic>n</italic>} into <italic>K </italic>segments, according to the likelihood, where <italic>n </italic>is the size of the sample. An exhaustive search becomes impossible for large <italic>K </italic>since the number of partitions of a set with <italic>n </italic>elements into <italic>K </italic>segments is <inline-graphic xlink:href="1471-2105-6-27-i8.gif"/>. To reduce the computational load, we use a dynamic programming approach (programs are coded in MATLAB language and are available upon request). Let <inline-graphic xlink:href="1471-2105-6-27-i19.gif"/> be the maximum log-likelihood obtained by the best partition of the data {<italic>Y</italic>(<italic>i</italic>), <italic>Y</italic>(<italic>i </italic>+ 1),...,<italic>Y</italic>(<italic>j</italic>)} into <italic>k </italic>+ 1 segments, with <italic>k </italic>break-points, and let note <inline-graphic xlink:href="1471-2105-6-27-i20.gif"/>. The algorithm is as follows:</p><p><inline-graphic xlink:href="1471-2105-6-27-i21.gif"/></p><p>Dynamic programming takes advantage of the additivity of the log-likelihood described above, considering that a partition of the data into <italic>k </italic>+ 1 segments is a union of a partition into <italic>k </italic>segments and a set containing 1 segment. This approach presents two main advantages: it provides an exact solution for the global optimum of the likelihood [<xref ref-type="bibr" rid="B17">17</xref>], and reduces the computational load from <inline-graphic xlink:href="1471-2105-6-27-i22.gif"/>(<italic>n</italic><sup><italic>K</italic></sup>) to <inline-graphic xlink:href="1471-2105-6-27-i22.gif"/>(<italic>n</italic><sup>2</sup>) for a given <italic>K </italic>(the algorithm only requires the storage of an upper <italic>n </italic>&#x000d7; <italic>n </italic>triangular matrix). At the end of the procedure, the quantities <inline-graphic xlink:href="1471-2105-6-27-i23.gif"/> are stored and will be used in the next step. Notice that this problem of partitioning is analogous to the search for the shortest path to travel from one point to another, where <inline-graphic xlink:href="1471-2105-6-27-i24.gif"/> represents the total length of a (<italic>k </italic>+ 1)-step-path connecting the point with coordinate 1 to the point with coordinate <italic>n</italic>.</p></sec><sec><title>An adaptive method to estimate the penalty constant</title><p>The purpose of this section is to explain an adaptive method to estimate the number of segments. Further theoretical developments can be found in [<xref ref-type="bibr" rid="B14">14</xref>]. If we consider that the likelihood <inline-graphic xlink:href="1471-2105-6-27-i5.gif"/> measures the adjustment of a model with <italic>K </italic>segments to the data, we aim at selecting the dimension for which <inline-graphic xlink:href="1471-2105-6-27-i5.gif"/> ceases to increase significantly. For this purpose, let us define a decreasing sequence (<italic>&#x003b2;</italic>) such as <italic>&#x003b2;</italic><sub>0 </sub>= &#x0221e; and</p><p><inline-graphic xlink:href="1471-2105-6-27-i25.gif"/></p><p>If we represent the curve (<italic>pen</italic>(<italic>K</italic>), <inline-graphic xlink:href="1471-2105-6-27-i5.gif"/>), the sequence of <italic>&#x003b2;</italic><sub><italic>i </italic></sub>represents the slopes between points (<italic>pen</italic>(<italic>K</italic><sub><italic>i </italic>+ 1</sub>), <inline-graphic xlink:href="1471-2105-6-27-i26.gif"/>) and (<italic>pen</italic>(<italic>K</italic><sub><italic>i</italic></sub>), <inline-graphic xlink:href="1471-2105-6-27-i27.gif"/>), where the subset {(<italic>pen</italic>(<italic>K</italic><sub><italic>i</italic></sub>),<inline-graphic xlink:href="1471-2105-6-27-i27.gif"/>),<italic>i </italic>&#x02265; 1}) is the convex hull of the set {(<italic>pen</italic>(<italic>K</italic>),<inline-graphic xlink:href="1471-2105-6-27-i5.gif"/>)}.</p><p>Since we aim at selecting the dimension for which <inline-graphic xlink:href="1471-2105-6-27-i5.gif"/> ceases to increase significantly, we look for breaks in the slope of the curve. We define <italic>l</italic><sub><italic>i</italic></sub>, the variation of the slope, that exactly corresponds to the length of the interval ]<italic>&#x003b2;</italic><sub><italic>i</italic></sub>, <italic>&#x003b2;</italic><sub><italic>i </italic>- 1</sub>] : <italic>l</italic><sub><italic>i </italic></sub>= <italic>&#x003b2;</italic><sub><italic>i </italic>- 1 </sub>- <italic>&#x003b2;</italic><sub><italic>i</italic></sub>. The length of these intervals is directly related to the second derivative of the likelihood. The automatic procedure to estimate the number of segments is then to calculate the second derivative (finite difference) of the likelihood:</p><p><inline-graphic xlink:href="1471-2105-6-27-i28.gif"/></p><p>and we select the highest number of segments <italic>K </italic>such that the second derivative is lower than a given threshold :</p><p><inline-graphic xlink:href="1471-2105-6-27-i29.gif"/></p><p>Other procedures have been developed to automatically locate the break in the slope of the likelihood. Nevertheless, the criterion we use can be interpreted geometrically and is easy to implement. The choice of the constant <italic>s </italic>is arbitrary. According to our experience, a threshold <italic>s </italic>= -0.5 seems appropriate for our purpose. A criticism that can be made to this procedure is its dependency on the threshold which is chosen. Nevertheless, it is important to point out that despite this thresholding the procedure remains adaptive, since the penalty constant is estimated according to the data.</p></sec><sec><title>Simulation studies</title><p>We performe numerical simulations to assess the sensitivity of our procedure to the addition of noise. In the first case, we simulate 100 points with <italic>K</italic>* = 5 segments. In the first case Figure <xref ref-type="fig" rid="F3">3</xref>, the segments are regularly spaced and the difference of the means between two segments is <italic>d </italic>= 1. In the second case (Figure <xref ref-type="fig" rid="F4">4</xref>) the segments are irregularly spaced and the difference of the means varies between <italic>d </italic>= 2 and <italic>d </italic>= 0.5. The standard deviation of the Gaussian errors varies from <italic>&#x003c3; </italic>= 0.1 to <italic>&#x003c3; </italic>= 2. Each configuration is simulated 500 times, and we calculate the average selected number of segments over 500 simulations. In order to assess the performance of the dynamic programming algorithm, we calculate the empirical probability over 500 simulations for a break-point to be located at coordinate <italic>t </italic>(for <italic>t </italic>= 1 to 100).</p></sec></sec><sec><title>Authors' contributions</title><p>FP developed the statistical models and the programs dedicated to array CGH data analysis, ML developped the adaptive selection of the number of segments. SR, CV and JJD supervised the study.</p></sec></body><back><ack><sec><title>Acknowledgements</title><p>The authors want to thank Prs D. Pinkel and D. G. Albertson, and Dr E. Lebarbier for helpful discussion and comments, and L. Spector for editing the manuscript. CV is supported by grant NIH RO1 DK60540.</p></sec></ack><ref-list><ref id="B1"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Albertson</surname><given-names>D</given-names></name><name><surname>Collins</surname><given-names>C</given-names></name><name><surname>McCormick</surname><given-names>F</given-names></name><name><surname>Gray</surname><given-names>J</given-names></name></person-group><article-title>Chromosome aberrations in solid tumors</article-title><source>Nature Genetics</source><year>2003</year><volume>34</volume><fpage>369</fpage><lpage>376</lpage><pub-id pub-id-type="pmid">12923544</pub-id><pub-id pub-id-type="doi">10.1038/ng1215</pub-id></citation></ref><ref id="B2"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Albertson</surname><given-names>D</given-names></name><name><surname>Pinkel</surname><given-names>D</given-names></name></person-group><article-title>Genomic Microarrays in Human Genetic Disease and Cancer</article-title><source>Human Molecular Genetics</source><year>2003</year><volume>12</volume><fpage>145</fpage><lpage>152</lpage><pub-id pub-id-type="pmid">12499395</pub-id><pub-id pub-id-type="doi">10.1093/hmg/ddg261</pub-id></citation></ref><ref id="B3"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Beheshti</surname><given-names>B</given-names></name><name><surname>Park</surname><given-names>P</given-names></name><name><surname>Braude</surname><given-names>I</given-names></name><name><surname>Squire</surname><given-names>J</given-names></name></person-group><source>Molecular Cytogenetics: Protocols and Applications</source><year>2002</year><publisher-name>Humana Press</publisher-name></citation></ref><ref id="B4"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Solinas-Toldo</surname><given-names>S</given-names></name><name><surname>Lampel</surname><given-names>S</given-names></name><name><surname>Stilgenbauer</surname><given-names>S</given-names></name><name><surname>Nickolenko</surname><given-names>J</given-names></name><name><surname>Benner</surname><given-names>A</given-names></name><name><surname>Dohner</surname><given-names>H</given-names></name><name><surname>Cremer</surname><given-names>T</given-names></name><name><surname>Lichter</surname><given-names>P</given-names></name></person-group><article-title>Matrix-based Comparative Genomic Hybridization: Biochips to Screen for Genomic Imbalances</article-title><source>Genes, Chromosomes and Cancer</source><year>1997</year><volume>20</volume><fpage>399</fpage><lpage>407</lpage><pub-id pub-id-type="pmid">9408757</pub-id><pub-id pub-id-type="doi">10.1002/(SICI)1098-2264(199712)20:4&#x0003c;399::AID-GCC12&#x0003e;3.0.CO;2-I</pub-id></citation></ref><ref id="B5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pinkel</surname><given-names>D</given-names></name><name><surname>Segraves</surname><given-names>R</given-names></name><name><surname>Sudar</surname><given-names>D</given-names></name><name><surname>Clark</surname><given-names>S</given-names></name><name><surname>Poole</surname><given-names>I</given-names></name><name><surname>Kowbel</surname><given-names>D</given-names></name><name><surname>Collins</surname><given-names>C</given-names></name><name><surname>Kuo</surname><given-names>W</given-names></name><name><surname>Chen</surname><given-names>C</given-names></name><name><surname>Zhai</surname><given-names>Y</given-names></name><name><surname>Dairkee</surname><given-names>S</given-names></name><name><surname>Ljung</surname><given-names>B</given-names></name><name><surname>Gray</surname><given-names>J</given-names></name></person-group><article-title>High resolution analysis of DNA copy number variation using comparative genomic hybridization to microarrays</article-title><source>Nature Genetics</source><year>1998</year><volume>20</volume><fpage>207</fpage><lpage>211</lpage><pub-id pub-id-type="pmid">9771718</pub-id><pub-id pub-id-type="doi">10.1038/2524</pub-id></citation></ref><ref id="B6"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Snijders</surname><given-names>AM</given-names></name><name><surname>Nowak</surname><given-names>N</given-names></name><name><surname>Segraves</surname><given-names>R</given-names></name><name><surname>Blakwood</surname><given-names>S</given-names></name><name><surname>Brown</surname><given-names>N</given-names></name><name><surname>Conroy</surname><given-names>J</given-names></name><name><surname>Hamilton</surname><given-names>G</given-names></name><name><surname>Hindle</surname><given-names>AK</given-names></name><name><surname>Huey</surname><given-names>B</given-names></name><name><surname>Kimura</surname><given-names>K</given-names></name><name><surname>Law</surname><given-names>S</given-names></name><name><surname>Myambo</surname><given-names>K</given-names></name><name><surname>Palmer</surname><given-names>J</given-names></name><name><surname>Ylstra</surname><given-names>B</given-names></name><name><surname>Yue</surname><given-names>JP</given-names></name><name><surname>Gray</surname><given-names>JW</given-names></name><name><surname>Jain</surname><given-names>A</given-names></name><name><surname>Pinkel</surname><given-names>D</given-names></name><name><surname>Albertson</surname><given-names>DG</given-names></name></person-group><article-title>Assembly of microarrays for genome-wide measurement of DNA copy number</article-title><source>Nature Genetics</source><year>2001</year><volume>29</volume><fpage>263</fpage><lpage>264</lpage><pub-id pub-id-type="pmid">11687795</pub-id><pub-id pub-id-type="doi">10.1038/ng754</pub-id></citation></ref><ref id="B7"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Autio</surname><given-names>R</given-names></name><name><surname>Hautaniemi</surname><given-names>S</given-names></name><name><surname>Kauraniemi</surname><given-names>P</given-names></name><name><surname>Yli-Harja</surname><given-names>O</given-names></name><name><surname>Astola</surname><given-names>J</given-names></name><name><surname>Wolf</surname><given-names>M</given-names></name><name><surname>Kallioniemi</surname><given-names>A</given-names></name></person-group><article-title>CGH-plotter: MATLAB toolbox for CGH-data analysis</article-title><source>Bioinformatics</source><year>2003</year><volume>13</volume><fpage>1714</fpage><lpage>1715</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btg230</pub-id></citation></ref><ref id="B8"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Eilers</surname><given-names>P</given-names></name><name><surname>Menezes</surname><given-names>R</given-names></name></person-group><article-title>Quantile smoothing of array CGH data</article-title><source>Bioinformatics</source><year>2004</year><comment></comment></citation></ref><ref id="B9"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Jong</surname><given-names>K</given-names></name><name><surname>Marchiori</surname><given-names>E</given-names></name><name><surname>van der Vaart</surname><given-names>A</given-names></name><name><surname>Ylstra</surname><given-names>B</given-names></name><name><surname>Weiss</surname><given-names>M</given-names></name><name><surname>Meijer</surname><given-names>G</given-names></name></person-group><source>Applications of Evolutionary Computing: EvoWorkshops 2003: Proceedings, Springer-Verlag Heidelberg, chap chromosomal breakpoint detection in human cancer</source><year>2003</year><volume>2611</volume><fpage>54</fpage><lpage>65</lpage></citation></ref><ref id="B10"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Olshen</surname><given-names>A</given-names></name><name><surname>Venkatraman</surname><given-names>E</given-names></name><name><surname>Lucito</surname><given-names>R</given-names></name><name><surname>Wigler</surname><given-names>M</given-names></name></person-group><article-title>Circular Binary segmentation for the analysis of array-based DNA copy number data</article-title><source>Biostatistics</source><year>2004</year><volume>5</volume><fpage>557</fpage><lpage>572</lpage><pub-id pub-id-type="pmid">15475419</pub-id><pub-id pub-id-type="doi">10.1093/biostatistics/kxh008</pub-id></citation></ref><ref id="B11"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hupe</surname><given-names>P</given-names></name><name><surname>Stransky</surname><given-names>N</given-names></name><name><surname>Thiery</surname><given-names>J</given-names></name><name><surname>Radvanyi</surname><given-names>F</given-names></name><name><surname>Barillot</surname><given-names>E</given-names></name></person-group><article-title>Analysis of array CGH data: from signal ratio to gain and loss of DNA regions</article-title><source>Bioinformatics</source><year>2004</year><volume>20</volume><fpage>3413</fpage><lpage>3422</lpage><pub-id pub-id-type="pmid">15381628</pub-id></citation></ref><ref id="B12"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Fridlyand</surname><given-names>J</given-names></name><name><surname>Snijders</surname><given-names>A</given-names></name><name><surname>Pinkel</surname><given-names>D</given-names></name><name><surname>Albertson</surname><given-names>D</given-names></name><name><surname>Jain</surname><given-names>A</given-names></name></person-group><article-title>Hidden Markov Models approach to the analysis of array CGH data</article-title><source>Journal of Multivariate Analysis</source><year>2004</year><volume>90</volume><fpage>132</fpage><lpage>1533</lpage><pub-id pub-id-type="doi">10.1016/j.jmva.2004.02.008</pub-id></citation></ref><ref id="B13"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Lebarbier</surname><given-names>E</given-names></name></person-group><article-title>Detecting Multiple Change-Points in the Mean of Gaussian Process by Model Selection</article-title><source>(to appear in) Signal Processing</source><year>2005</year></citation></ref><ref id="B14"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Lavielle</surname><given-names>M</given-names></name></person-group><article-title>Using penalized contrasts for the change-point problem</article-title><source>(to appear in) Signal Processing</source><year>2005</year></citation></ref><ref id="B15"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ishkanian</surname><given-names>A</given-names></name><name><surname>Malloff</surname><given-names>C</given-names></name><name><surname>Watson</surname><given-names>S</given-names></name><name><surname>deLeeuw</surname><given-names>R</given-names></name><name><surname>Chi</surname><given-names>B</given-names></name><name><surname>Coe</surname><given-names>B</given-names></name><name><surname>Snijders</surname><given-names>A</given-names></name><name><surname>Albertson</surname><given-names>D</given-names></name><name><surname>Pinkel</surname><given-names>D</given-names></name><name><surname>Marra</surname><given-names>M</given-names></name><name><surname>Ling</surname><given-names>V</given-names></name><name><surname>MacAulay</surname><given-names>C</given-names></name><name><surname>Lam</surname><given-names>W</given-names></name></person-group><article-title>A tiling resolution DNA microarray with complete coverage of the human genome</article-title><source>Nature Genetics</source><year>2004</year><volume>36</volume><fpage>299</fpage><lpage>303</lpage><pub-id pub-id-type="pmid">14981516</pub-id><pub-id pub-id-type="doi">10.1038/ng1307</pub-id></citation></ref><ref id="B16"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Nakao</surname><given-names>K</given-names></name><name><surname>Mehta</surname><given-names>K</given-names></name><name><surname>Fridlyand</surname><given-names>J</given-names></name><name><surname>Moore</surname><given-names>DH</given-names></name><name><surname>Jain</surname><given-names>AJ</given-names></name><name><surname>Lafuente</surname><given-names>A</given-names></name><name><surname>Wiencke</surname><given-names>J</given-names></name><name><surname>Terdiman</surname><given-names>J</given-names></name><name><surname>Waldman</surname><given-names>F</given-names></name></person-group><article-title>High-resolution analysis of DNA copy number alterations in colorectal cancer by array-based comparative genomic hybridization</article-title><source>Carcinogenesis</source><year>2004</year><volume>25</volume><fpage>1345</fpage><lpage>1357</lpage><pub-id pub-id-type="pmid">15001537</pub-id><pub-id pub-id-type="doi">10.1093/carcin/bgh134</pub-id></citation></ref><ref id="B17"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Auger</surname><given-names>I</given-names></name><name><surname>Lawrence</surname><given-names>C</given-names></name></person-group><article-title>Algorithms for the optimal identification of segments neighborhoods</article-title><source>Bull Math Biol</source><year>1989</year><volume>51</volume><fpage>39</fpage><lpage>54</lpage><pub-id pub-id-type="pmid">2706400</pub-id></citation></ref></ref-list><sec sec-type="display-objects"><title>Figures and Tables</title><fig position="float" id="F1"><label>Figure 1</label><caption><p><bold>Results of the segmentation procedure when using the Bayesian Information Criterion (BIC) and the proposed criterion. </bold>Data shown corresponds to Coriell cell lines GM03563, chromosome 3. Red lines represent the estimated mean of each segments, and green lines, the estimated mean plus one standard deviation.</p></caption><graphic xlink:href="1471-2105-6-27-1"/></fig><fig position="float" id="F2"><label>Figure 2</label><caption><p><bold>Estimated number of segments for 4 different penalized criteria in the regular case (top) and the irregular case (bottom). </bold>Top : Results of the simulations for 5 regularly spaced segments with n = 100 data points. The graph represents the average estimated number of segments for each criterion according to the standard deviation of the noise (<italic>&#x003c3;</italic>). Bottom: Results of the simulations for 5 unregularly spaced segments with <italic>n </italic>= 100 data points. The adaptive criterion is robust to the additional noise since it maintains an estimate close to 5 segments whatever the noise and the configuration.</p></caption><graphic xlink:href="1471-2105-6-27-2"/></fig><fig position="float" id="F3"><label>Figure 3</label><caption><p><bold>Example of a simulation in the regular case, and result of the dynamic programming algorithm for the estimation of the break-point coordinates. </bold>Top: Example of simulation for 100 data points and 5 segments in the regular case. The true break-points are designated by vertical lines, and the red lines correspond to the mean of each segment. The difference of means <italic>d </italic>is constant and equals 1. Bottom: Estimated frequency for a break-point to be located at coordinate <italic>t </italic>for <italic>t </italic>= 1 to 100. Different levels of noise are considered with <italic>&#x003c3; </italic>= 0.1, <italic>&#x003c3; </italic>= 0.5, <italic>&#x003c3; </italic>= 1.</p></caption><graphic xlink:href="1471-2105-6-27-3"/></fig><fig position="float" id="F4"><label>Figure 4</label><caption><p><bold>Example of a simulation in the irregular case, and result of the dynamic programming algorithm for the estimation of the break-point coordinates. </bold>Top: Example of simulation for 100 data points and 5 segments in the irregular case. The true break-points are designated by vertical lines, and the red lines correspond to the mean of each segment. The difference of means varies between <italic>d </italic>= 2 to <italic>d </italic>= 0.5. Bottom: Estimated probability for a break-point to be located at coordinate <italic>t </italic>for <italic>t </italic>= 1 to 100. Different levels of noise are considered with <italic>&#x003c3; </italic>= 0.1, <italic>&#x003c3; </italic>= 0.5, <italic>&#x003c3; </italic>= 1.</p></caption><graphic xlink:href="1471-2105-6-27-4"/></fig><fig position="float" id="F5"><label>Figure 5</label><caption><p><bold>Comparison of segmentation results based on Breast Cancer Cell lines using the adaptive criterion and Jong criterion. </bold>Results of the segmentation procedure for Breast cancer cell lines Bt474, chromosomes 9 and 10. Fluoresence log<sub>2</sub>-ratios are plotted according to their location on the genome in megabases. Left profiles are segmented using the adaptive criterion and right profiles using Jong's criterion. The adaptive method detects a break-point at 1.58 MB on chromosome 9 that seems to be an outlier, and detects a putative deleted region on chromosome 10 at 1.76 MB.</p></caption><graphic xlink:href="1471-2105-6-27-5"/></fig><fig position="float" id="F6"><label>Figure 6</label><caption><p><bold>Comparison of segmentation results based on colorectal cancer data, using model </bold><inline-graphic xlink:href="1471-2105-6-27-i2.gif"/><bold>and </bold><inline-graphic xlink:href="1471-2105-6-27-i3.gif"/>. Results of the segmentation procedure for colorectal cancer data, chromosome 1 and chromosome 8. Fluoresence log<sub>2</sub>-ratios are plotted according to their location on the genome in megabases. Left profiles are segmented using model <inline-graphic xlink:href="1471-2105-6-27-i2.gif"/>, and right profiles using model <inline-graphic xlink:href="1471-2105-6-27-i3.gif"/>. Our criterion is used to estimate the number of segments.</p></caption><graphic xlink:href="1471-2105-6-27-6"/></fig><table-wrap position="float" id="T1"><label>Table 1</label><caption><p>Constants and penalty funtions for different penalized criteria, in a heteroscedastic model with <italic>K </italic>segments.</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left">criterion</td><td align="center"><italic>&#x003b2;</italic></td><td align="center"><italic>pen</italic>(<italic>K</italic>)</td></tr></thead><tbody><tr><td align="left">AIC</td><td align="center">I</td><td align="center">2<italic>K</italic></td></tr><tr><td align="left">BIG</td><td align="center"><graphic xlink:href="1471-2105-6-27-i9.gif"/></td><td align="center">2<italic>K</italic></td></tr><tr><td align="left">Jong (2003)</td><td align="center">10/3</td><td align="center">3<italic>K </italic>- 1</td></tr><tr><td align="left">Lebarbier (2003)</td><td align="center">adaptive</td><td align="center"><graphic xlink:href="1471-2105-6-27-i10.gif"/></td></tr><tr><td align="left">Lavielle (2003)</td><td align="center">adaptive</td><td align="center">2<italic>K</italic></td></tr></tbody></table></table-wrap></sec></back></article>



